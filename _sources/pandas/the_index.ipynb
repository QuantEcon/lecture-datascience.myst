{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4dc510",
   "metadata": {},
   "source": [
    "# The Index\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- {doc}`Introduction to pandas <intro>`\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand how the index is used to align data\n",
    "- Know how to set and reset the index\n",
    "- Understand how to select subsets of data by slicing on index and columns\n",
    "- Understand that for DataFrames, the column names also align data\n",
    "\n",
    "\n",
    "```{literalinclude} ../_static/colab_light.raw\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb00790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd154c",
   "metadata": {},
   "source": [
    "## So What is this Index?\n",
    "\n",
    "Every Series or DataFrame has an index.\n",
    "\n",
    "We told you that the index was the \"row labels\" for the data.\n",
    "\n",
    "This is true, but an index in pandas does much more than label the rows.\n",
    "\n",
    "The purpose of this lecture is to understand the importance of the index.\n",
    "\n",
    "The [pandas\n",
    "documentation](https://pandas.pydata.org/pandas-docs/stable/dsintro.html)\n",
    "says\n",
    "\n",
    "> Data alignment is intrinsic. The link between labels and data will\n",
    "> not be broken unless done so explicitly by you.\n",
    "\n",
    "In practice, the index and column names are used to make sure the data is\n",
    "properly aligned when operating on multiple DataFrames.\n",
    "\n",
    "This is a somewhat abstract concept that is best understood by\n",
    "example...\n",
    "\n",
    "Let's begin by loading some data on GDP components that we collected from\n",
    "the World Bank's World Development Indicators Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a546ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://datascience.quantecon.org/assets/data/wdi_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    722\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:363\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    362\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    364\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "url = \"https://datascience.quantecon.org/assets/data/wdi_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.info()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6064a4",
   "metadata": {},
   "source": [
    "We'll also extract a couple smaller DataFrames we can use in examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abed536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.head(5)\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny = df.iloc[[0, 3, 2, 4], :]\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4950b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_ex = df_small[[\"Imports\", \"Exports\"]]\n",
    "im_ex_copy = im_ex.copy()\n",
    "im_ex_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d565a",
   "metadata": {},
   "source": [
    "Observe what happens when we evaluate `im_ex + im_ex_copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5731090",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_ex + im_ex_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c8a31e",
   "metadata": {},
   "source": [
    "Notice that this operated *elementwise*, meaning that the `+`\n",
    "operation was applied to each element of `im_ex` and the corresponding\n",
    "element of `im_ex_copy`.\n",
    "\n",
    "Let's take a closer look at `df_tiny`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec42b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33218ff6",
   "metadata": {},
   "source": [
    "Relative to `im_ex` notice a few things:\n",
    "\n",
    "- The row labeled `1` appears in `im_ex` but not `df_tiny`.\n",
    "- For row labels that appear in both, they are not in the same position\n",
    "  within each DataFrame.\n",
    "- Certain columns appear only in `df_tiny`.\n",
    "- The `Imports` and `Exports` columns are the 6th and 5th columns of\n",
    "  `df_tiny` and the 1st and 2nd of `im_ex`, respectively.\n",
    "\n",
    "Now, let's see what happens when we try `df_tiny + im_ex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_ex_tiny = df_tiny + im_ex\n",
    "im_ex_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c71d92",
   "metadata": {},
   "source": [
    "Whoa, a lot happened! Let's break it down.\n",
    "\n",
    "### Automatic Alignment\n",
    "\n",
    "For all (row, column) combinations that appear in both DataFrames (e.g.\n",
    "rows `[1, 3]` and columns `[Imports, Exports]`), the value of `im_ex_tiny`\n",
    "is equal to `df_tiny.loc[row, col] + im_ex.loc[row, col]`.\n",
    "\n",
    "This happened even though the rows and columns were not in the same\n",
    "order.\n",
    "\n",
    "We refer to this as pandas *aligning* the data for us.\n",
    "\n",
    "To see how awesome this is, think about how to do something similar in\n",
    "Excel:\n",
    "\n",
    "- `df_tiny` and `im_ex` would be in different sheets.\n",
    "- The index and column names would be the first column and row in each\n",
    "  sheet.\n",
    "- We would have a third sheet to hold the sum.\n",
    "- For each label in the first row and column of *either* the `df_tiny`\n",
    "  sheet or the `im_ex` sheet we would have to do a `IFELSE` to check\n",
    "  if the label exists in the other sheet and then a `VLOOKUP` to\n",
    "  extract the value.\n",
    "\n",
    "In pandas, this happens automatically, behind the scenes, and *very\n",
    "quickly*.\n",
    "\n",
    "### Handling Missing Data\n",
    "\n",
    "For all elements in row `1` or columns\n",
    "`[\"country\", \"year\", \"GovExpend\", \"Consumption\", \"GDP\"]`,\n",
    "the value in `im_ex_tiny` is `NaN`.\n",
    "\n",
    "This is how pandas represents *missing data*.\n",
    "\n",
    "So, when pandas was trying to look up the values in `df_tiny` and `im_ex`, it could\n",
    "only find a value in one DataFrame: the other value was missing.\n",
    "\n",
    "When pandas tries to add a number to something that is missing, it says\n",
    "that the result is missing (spelled `NaN`).\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-idx-dir1\n",
    "See exercise 1 in the {ref}`exercise list <pd-idx-ex>`.\n",
    "````\n",
    "\n",
    "## Setting the Index\n",
    "\n",
    "For a DataFrame `df`, the `df.set_index` method allows us to use one\n",
    "(or more) of the DataFrame's columns as the index.\n",
    "\n",
    "Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create the DataFrame\n",
    "df_year = df.set_index([\"year\"])\n",
    "df_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e453ad",
   "metadata": {},
   "source": [
    "Now that the year is on the index, we can use `.loc` to extract all the\n",
    "data for a specific year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.loc[2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3801ad",
   "metadata": {},
   "source": [
    "This would be helpful, for example, if we wanted to compute the difference\n",
    "in the average of all our variables from one year to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.loc[2009].mean() - df_year.loc[2008].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc20909",
   "metadata": {},
   "source": [
    "Notice that pandas did a few things for us.\n",
    "\n",
    "- After computing `.mean()`, the row labels (index) were the former column names.\n",
    "- These column names were used to align data when we wanted asked pandas to\n",
    "  compute the difference.\n",
    "\n",
    "Suppose that someone asked you, \"What was the GDP in the US in 2010?\"\n",
    "\n",
    "To compute that using `df_year` you might do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.loc[df_year[\"country\"] == \"United States\", \"GDP\"].loc[2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717ab7d",
   "metadata": {},
   "source": [
    "That was a lot of work!\n",
    "\n",
    "Now, suppose that after seeing you extract that data, your friend asks you\n",
    "\"What about GDP in Germany and the UK in 2010?\"\n",
    "\n",
    "To answer that question, you might write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.loc[df_year[\"country\"].isin([\"United Kingdom\", \"Germany\"]), \"GDP\"].loc[2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f68f26",
   "metadata": {},
   "source": [
    "Notice that this code is similar to the code above, but now provides a result\n",
    "that is ambiguous.\n",
    "\n",
    "The two elements in the series both have with label 2010.\n",
    "\n",
    "How do we know which is which?\n",
    "\n",
    "We might think that the first value corresponds to the United Kingdom because\n",
    "that is what we listed first in the call to `isin`, but we would be wrong!\n",
    "\n",
    "Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.loc[2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a16cc4",
   "metadata": {},
   "source": [
    "Setting just the year as index has one more potential issue: we will\n",
    "get data alignment only on the year, which may not be sufficient.\n",
    "\n",
    "To demonstrate this point, suppose now you are asked to use our WDI dataset\n",
    "to compute an approximation for net exports and investment in 2009.\n",
    "\n",
    "As a seasoned economist, you would remember the expenditure formula for GDP is\n",
    "written\n",
    "\n",
    "$$\n",
    "GDP = Consumption + Investment + GovExpend + Net Exports\n",
    "$$\n",
    "\n",
    "which we can rearrange to compute investment as a function of the variables in\n",
    "our DataFrame...\n",
    "\n",
    "$$\n",
    "Investment = GDP - Consumption - GovExpend - Net Exports\n",
    "$$\n",
    "\n",
    "Note that we can compute NetExports as `Exports - Imports`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = df_year[\"Exports\"] - df_year[\"Imports\"]\n",
    "nx.head(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1ced7",
   "metadata": {},
   "source": [
    "Now, suppose that we accidentally had a bug in our code that swapped\n",
    "the data for Canada and Germany's net exports in 2017.\n",
    "\n",
    "```{note}\n",
    "This example is contrived, but if you were getting unclean data from\n",
    "some resource or doing more complicated operations, this type of mistake\n",
    "becomes increasingly likely.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca17 = nx.iloc[[0]]\n",
    "g17 = nx.iloc[[18]]\n",
    "nx.iloc[[0]] = g17\n",
    "nx.iloc[[18]] = ca17\n",
    "\n",
    "nx.head(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95136f7b",
   "metadata": {},
   "source": [
    "Notice that if we now add `nx` to the DataFrame and compute investment\n",
    "pandas doesn't complain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year[\"NetExports\"] = nx\n",
    "df_year[\"Investment\"] = df_year.eval(\"GDP - Consumption - GovExpend - NetExports\")\n",
    "df_year.head(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b469dd0",
   "metadata": {},
   "source": [
    "Because we didn't also have data alignment on the country, we would have overstated Canada's investment by 281 billion USD and understated Germany's by the\n",
    "same amount.\n",
    "\n",
    "To make these types operation easier, we need to include both the year\n",
    "and country in the index...\n",
    "\n",
    "### Setting a Hierarchical Index\n",
    "\n",
    "Include multiple columns in the index is advantageous in some situations.\n",
    "\n",
    "These situations might include:\n",
    "\n",
    "- When we need more than one piece of information (column) to identify an\n",
    "  observation (as in the Germany and UK GDP example above)\n",
    "- When we need data-alignment by more than one column\n",
    "\n",
    "To achieve multiple columns in the index, we pass a list of multiple column\n",
    "names to `set_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbd196",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi = df.set_index([\"country\", \"year\"])\n",
    "wdi.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3db268",
   "metadata": {},
   "source": [
    "Notice that in the display above, the row labels seem to have two\n",
    "*levels* now.\n",
    "\n",
    "The *outer* (or left-most) level is named `country` and the *inner* (or\n",
    "right-most) level is named `year`.\n",
    "\n",
    "When a DataFrame's index has multiple levels, we (and the pandas documentation)\n",
    "refer to the DataFrame as having a hierarchical index.\n",
    "\n",
    "### Slicing a Hierarchical Index\n",
    "\n",
    "Now, we can answer our friend's questions in a much more straightforward way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.loc[(\"United States\", 2010), \"GDP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.loc[([\"United Kingdom\", \"Germany\"], 2010), \"GDP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84540e17",
   "metadata": {},
   "source": [
    "As shown above, we can use `wdi.loc` to extract different slices of our\n",
    "national accounts data.\n",
    "\n",
    "The rules for using `.loc` with a hierarchically-indexed DataFrame are\n",
    "similar to the ones we've learned for standard DataFrames, but they are a bit\n",
    "more elaborate as we now have more structure to our data.\n",
    "\n",
    "We will summarize the main rules, and then work through an exercise that\n",
    "demonstrates each of them.\n",
    "\n",
    "**Slicing rules**\n",
    "\n",
    "pandas slicing reacts differently to `list`s and `tuple`s.\n",
    "\n",
    "It does this to provide more flexibility to select the\n",
    "data you want.\n",
    "\n",
    "`list` in row slicing will be an \"or\" operation, where it chooses rows\n",
    "based on whether the index value corresponds to any element of the list.\n",
    "\n",
    "`tuple` in row slicing will be used to denote a single hierarchical\n",
    "index and must include a value for each level.\n",
    "\n",
    "**Row slicing examples**\n",
    "\n",
    "1. `wdi.loc[\"United States\"]`: all rows where the *outer* most index value is\n",
    "   equal to `United States`\n",
    "1. `wdi.loc[(\"United States\", 2010)]`: all rows where the *outer-most* index value\n",
    "   is equal to `\"United States` and the second level is equal to `2010`\n",
    "1. `wdi.loc[[\"United States\", \"Canada\"]]`: all rows where the *outer-most* index is\n",
    "   either `\"United States\"` or `\"Canada\"`\n",
    "1. `wdi.loc[([\"United States\", \"Canada\"], [2010, 2011]), :]`: all rows where the\n",
    "   *outer-most* index is either `\"United States` or `\"Canada\"` AND where the\n",
    "   second level index is either `2010` or `2011`\n",
    "1. `wdi.loc[[(\"United States\", 2010), (\"Canada\", 2011)], :]`: all rows where the the\n",
    "   two hierarchical indices are either `(\"United States\", 2010)` or\n",
    "   `(\"Canada\", 2011)`\n",
    "\n",
    "We can also restrict `.loc` to extract certain columns by doing:\n",
    "\n",
    "1. `wdi.loc[rows, GDP]`: return the rows specified by rows (see rules\n",
    "   above) and only column named `GDP` (returned object will be a\n",
    "   Series)\n",
    "1. `df.loc[rows, [\"GDP\", \"Consumption\"]]`: return the rows specified by rows\n",
    "   (see rules above) and only columns `GDP` and `Consumption`\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-idx-dir2\n",
    "See exercise 2 in the {ref}`exercise list <pd-idx-ex>`.\n",
    "````\n",
    "\n",
    "### Alignment with `MultiIndex`\n",
    "\n",
    "The data alignment features we talked about above also apply to a\n",
    "`MultiIndex` DataFrame.\n",
    "\n",
    "The exercise below gives you a chance to experiment with this.\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-idx-dir3\n",
    "See exercise 3 in the {ref}`exercise list <pd-idx-ex>`.\n",
    "````\n",
    "\n",
    "### `pd.IndexSlice`\n",
    "\n",
    "When we want to extract rows for a few values of the outer index and all\n",
    "values for an inner index level, we can use the convenient\n",
    "`df.loc[[id11, id22]]` shorthand.\n",
    "\n",
    "We can use this notation to extract all the data for the United States and\n",
    "Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.loc[[\"United States\", \"Canada\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54f7de",
   "metadata": {},
   "source": [
    "However, suppose we wanted to extract the data for all countries, but only the\n",
    "years 2005, 2007, and 2009.\n",
    "\n",
    "We cannot do this using `wdi.loc` because the year is on the second level,\n",
    "not outer-most level of our index.\n",
    "\n",
    "To get around this limitation, we can use the `pd.IndexSlice` helper.\n",
    "\n",
    "Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.loc[pd.IndexSlice[:, [2005, 2007, 2009]], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12094218",
   "metadata": {},
   "source": [
    "Notice that the `:` in the first part of `[:, [\"A\", \"D\"]]`\n",
    "instructed pandas to give us rows for all values of the outer most index\n",
    "level and that the `:` just before `]` said grab all the columns.\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-idx-dir4\n",
    "See exercise 4 in the {ref}`exercise list <pd-idx-ex>`.\n",
    "````\n",
    "\n",
    "### Multi-index Columns\n",
    "\n",
    "The functionality of `MultiIndex` also applies to the column names.\n",
    "\n",
    "Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdiT = wdi.T  # .T means \"transpose\" or \"swap rows and columns\"\n",
    "wdiT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd85fc",
   "metadata": {},
   "source": [
    "Notice that `wdiT` seems to have two levels of names for the columns.\n",
    "\n",
    "The same logic laid out in the above row slicing rules applies when we\n",
    "have a hierarchical index for column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d51c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdiT.loc[:, \"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdiT.loc[:, [\"United States\", \"Canada\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa141cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdiT.loc[:, ([\"United States\", \"Canada\"], 2010)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5fb279",
   "metadata": {},
   "source": [
    "````{admonition} Exercise\n",
    ":name: pd-idx-dir5\n",
    "See exercise 5 in the {ref}`exercise list <pd-idx-ex>`.\n",
    "````\n",
    "\n",
    "## Re-setting the Index\n",
    "\n",
    "The `df.reset_index` method will move one or more level of the index\n",
    "back into the DataFrame as a normal column.\n",
    "\n",
    "With no additional arguments, it moves all levels out of the index and\n",
    "sets the index of the returned DataFrame to the default of\n",
    "`range(df.shape[0])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072b881",
   "metadata": {},
   "source": [
    "````{admonition} Exercise\n",
    ":name: pd-idx-dir6\n",
    "See exercise 6 in the {ref}`exercise list <pd-idx-ex>`.\n",
    "````\n",
    "\n",
    "## Choose the Index Carefully\n",
    "\n",
    "So, now that we know that we use index and column names for\n",
    "aligning data, \"how should we pick the index?\" is a natural question to ask.\n",
    "\n",
    "To guide us to the right answer, we will list the first two components\n",
    "to [Hadley Wickham's](http://hadley.nz/) description of [tidy\n",
    "data](http://vita.had.co.nz/papers/tidy-data.html):\n",
    "\n",
    "1. Each column should each have one variable.\n",
    "1. Each row should each have one observation.\n",
    "\n",
    "If we strive to have our data in a tidy form (we should), then when\n",
    "choosing the index, we should set:\n",
    "\n",
    "- the row labels (index) to be a unique identifier for an observation\n",
    "  of data\n",
    "- the column names to identify one variable\n",
    "\n",
    "For example, suppose we are looking data on interest rates.\n",
    "\n",
    "Each column might represent one bond or asset and each row might\n",
    "represent the date.\n",
    "\n",
    "Using hierarchical row and column indices allows us to store higher\n",
    "dimensional data in our (inherently) two dimensional DataFrame.\n",
    "\n",
    "### Know Your Goal\n",
    "\n",
    "The correct column(s) to choose for the index often depends on the context of\n",
    "your analysis.\n",
    "\n",
    "For example, if I were studying how GDP and consumption evolved over time for\n",
    "various countries, I would want time (year) and country name on the index\n",
    "\n",
    "On the other hand, if I were trying to look at the differences across countries\n",
    "and variables within a particular year, I may opt to put the country and\n",
    "variable on the index and have years be columns.\n",
    "\n",
    "Following the tidy data rules above and thinking about how you intend to *use*\n",
    "the data -- and a little practice -- will enable you to consistently select the\n",
    "correct index.\n",
    "\n",
    "(pd-idx-ex)=\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "What happens when you apply the `mean` method to `im_ex_tiny`?\n",
    "\n",
    "In particular, what happens to columns that have missing data? \n",
    "```{hint}\n",
    "Also looking at the output of the `sum` method might help.\n",
    "```\n",
    "\n",
    "({ref}`back to text <pd-idx-dir1>`)\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "For each of the examples below do the following:\n",
    "\n",
    "- Determine which of the rules above applies.\n",
    "- Identify the `type` of the returned value.\n",
    "- Explain why the slicing operation returned the data it did.\n",
    "\n",
    "Write your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d41b70",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[[\"United States\", \"Canada\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188330eb",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[([\"United States\", \"Canada\"], [2010, 2011, 2012]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498bb673",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[\"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e197c0",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[(\"United States\", 2010), [\"GDP\", \"Exports\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2466c",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[(\"United States\", 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee5bd3",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[[(\"United States\", 2010), (\"Canada\", 2015)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c96e64",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[[\"United States\", \"Canada\"], \"GDP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b0112",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi.loc[\"United States\", \"GDP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd9c43",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-idx-dir2>`)\n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "Try setting `my_df` to some subset of the rows in `wdi` (use one of the\n",
    "`.loc` variations above).\n",
    "\n",
    "Then see what happens when you do `wdi / my_df` or `my_df ** wdi`.\n",
    "\n",
    "Try changing the subset of rows in `my_df` and repeat until you\n",
    "understand what is happening.\n",
    "\n",
    "({ref}`back to text <pd-idx-dir3>`)\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "Below, we create `wdi2`, which is the same as `df4` except that the\n",
    "levels of the index are swapped.\n",
    "\n",
    "In the cells after `df6` is defined, we have commented out\n",
    "a few of the slicing examples from the previous exercise.\n",
    "\n",
    "For each of these examples, use `pd.IndexSlice` to extract the same\n",
    "data from `df6`.\n",
    "\n",
    "```{hint}\n",
    "You will need to *swap* the order of the row slicing arguments\n",
    "within the `pd.IndexSlice`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9e158",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "wdi2 = df.set_index([\"year\", \"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38101a8",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# wdi.loc[\"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3983cff",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# wdi.loc[([\"United States\", \"Canada\"], [2010, 2011, 2012]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec751465",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# wdi.loc[[\"United States\", \"Canada\"], \"GDP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5531a",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-idx-dir4>`)\n",
    "\n",
    "### Exercise 5\n",
    "\n",
    "Use `pd.IndexSlice` to extract all data from `wdiT` where the `year`\n",
    "level of the column names (the second level) is one of 2010, 2012, and 2014\n",
    "\n",
    "({ref}`back to text <pd-idx-dir5>`)\n",
    "\n",
    "### Exercise 6\n",
    "\n",
    "Look up the documentation for the `reset_index` method and study it to\n",
    "learn how to do the following:\n",
    "\n",
    "- Move just the `year` level of the index back as a column.\n",
    "- Completely throw away all levels of the index.\n",
    "- Remove the `country` of the index and *do not* keep it as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8258686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove just year level and add as column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0437243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw away all levels of index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69571b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove country from the index -- don't keep it as a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d99d0",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-idx-dir6>`)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "source_map": [
   10,
   29,
   32,
   60,
   66,
   70,
   75,
   80,
   84,
   88,
   90,
   98,
   100,
   113,
   116,
   172,
   176,
   181,
   183,
   188,
   190,
   202,
   204,
   213,
   215,
   229,
   231,
   255,
   258,
   269,
   276,
   281,
   285,
   306,
   309,
   324,
   328,
   330,
   404,
   406,
   418,
   420,
   437,
   440,
   447,
   451,
   455,
   457,
   473,
   475,
   549,
   554,
   559,
   564,
   569,
   574,
   579,
   584,
   587,
   619,
   624,
   629,
   634,
   637,
   657,
   661,
   665,
   667
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}