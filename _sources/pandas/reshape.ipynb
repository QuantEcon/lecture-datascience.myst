{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cf6088",
   "metadata": {},
   "source": [
    "# Reshape\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- {doc}`pandas intro <intro>`\n",
    "- {doc}`pandas basics <basics>`\n",
    "- {doc}`Importance of index <the_index>`\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand and be able to apply the `melt`/`stack`/`unstack`/`pivot` methods\n",
    "- Practice transformations of indices\n",
    "- Understand tidy data\n",
    "\n",
    "```{literalinclude} ../_static/colab_light.raw\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2903e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0d580",
   "metadata": {},
   "source": [
    "## Tidy Data\n",
    "\n",
    "While pushed more generally in the `R` language, the concept of \"[tidy data](https://en.wikipedia.org/wiki/Tidy_data)\" is helpful in understanding the\n",
    "objectives for reshaping data, which in turn makes advanced features like\n",
    "{doc}`groupby <groupby>` more seamless.\n",
    "\n",
    "Hadley Wickham gives a terminology slightly better-adapted for the experimental\n",
    "sciences, but nevertheless useful for the social sciences.\n",
    "\n",
    "> A dataset is a collection of values, usually either numbers (if quantitative) or strings (if qualitative). Values are organized in two ways. Every value belongs to a variable and an observation. A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An observation contains all values measured on the same unit (like a person, or a day, or a race) across attributes. -- [Tidy Data (Journal of Statistical Software 2013)](https://www.jstatsoft.org/index.php/jss/article/view/v059i10/v59i10.pdf)\n",
    "\n",
    "With this framing,\n",
    "\n",
    "> A dataset is messy or tidy depending on how rows, columns and tables are\n",
    "> matched with observations, variables, and types. In tidy data:\n",
    ">\n",
    "> 1.  Each variable forms a column.\n",
    ">\n",
    "> 2.  Each observation forms a row.\n",
    ">\n",
    "> 3.  Each type of observational unit forms a table.\n",
    "\n",
    "The \"column\" and \"row\" terms map directly to pandas columns and rows, while the\n",
    "\"table\" maps to a pandas DataFrame.\n",
    "\n",
    "With this thinking and interpretation, it becomes essential to think through\n",
    "what uniquely identifies an \"observation\" in your data.\n",
    "\n",
    "Is it a country? A year? A combination of country and year?\n",
    "\n",
    "These will become the indices of your DataFrame.\n",
    "\n",
    "For those with more of a database background, the \"tidy\" format matches the\n",
    "[3rd normal form](https://en.wikipedia.org/wiki/Third_normal_form) in\n",
    "database theory, where the referential integrity of the database is maintained\n",
    "by the uniqueness of the index.\n",
    "\n",
    "When considering how to map this to the social sciences, note that\n",
    "reshaping data can change what we consider to be the variable and\n",
    "observation in a way that doesn't occur within the natural sciences.\n",
    "\n",
    "For example, if the \"observation\" uniquely identified by a country and year and\n",
    "the \"variable\" is GDP, you may wish to reshape it so that the \"observable\" is a\n",
    "country, and the variables are a GDP for each year.\n",
    "\n",
    "A word of caution: The tidy approach, where there is no redundancy and each\n",
    "type of observational unit forms a table, is a good approach for storing data,\n",
    "but you will frequently reshape/merge/etc. in order to make graphing or\n",
    "analysis easier.  This doesn't break the tidy format since those examples are\n",
    "ephemeral states used in analysis.\n",
    "\n",
    "## Reshaping your Data\n",
    "\n",
    "The data you receive is not always in a \"shape\" that makes it easy to analyze.\n",
    "\n",
    "What do we mean by shape? The number of rows and columns in a\n",
    "DataFrame and how information is stored in the index and column names.\n",
    "\n",
    "This lecture will teach you the basic concepts of reshaping data.\n",
    "\n",
    "As with other topics, we recommend reviewing the [pandas\n",
    "documentation](https://pandas.pydata.org/pandas-docs/stable/reshaping.html)\n",
    "on this subject for additional information.\n",
    "\n",
    "We will keep our discussion here as brief and simple as possible because\n",
    "these tools will reappear in subsequent lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c65233a",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://datascience.quantecon.org/assets/data/bball.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m bball \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m bball\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m      5\u001b[0m bball\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    722\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:363\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    362\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    364\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "url = \"https://datascience.quantecon.org/assets/data/bball.csv\"\n",
    "bball = pd.read_csv(url)\n",
    "bball.info()\n",
    "\n",
    "bball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d87633",
   "metadata": {},
   "source": [
    "## Long vs Wide\n",
    "\n",
    "Many of these operations change between long and wide DataFrames.\n",
    "\n",
    "What does it mean for a DataFrame to be long or wide?\n",
    "\n",
    "Here is long possible long-form representation of our basketball data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64330e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about what this command does -- We'll see it soon\n",
    "bball_long = bball.melt(id_vars=[\"Year\", \"Player\", \"Team\", \"TeamName\"])\n",
    "\n",
    "bball_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae0c1d",
   "metadata": {},
   "source": [
    "And here is a wide-form version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b403bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, don't worry about this command... We'll see it soon too\n",
    "bball_wide = bball_long.pivot_table(\n",
    "    index=\"Year\",\n",
    "    columns=[\"Player\", \"variable\", \"Team\"],\n",
    "    values=\"value\"\n",
    ")\n",
    "bball_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ced02f",
   "metadata": {},
   "source": [
    "## `set_index`, `reset_index`, and Transpose\n",
    "\n",
    "We have already seen a few basic methods for reshaping a\n",
    "DataFrame.\n",
    "\n",
    "- `set_index`: Move one or more columns into the index.\n",
    "- `reset_index`: Move one or more index levels out of the index and make\n",
    "  them either columns or drop from DataFrame.\n",
    "- `T`: Swap row and column labels.\n",
    "\n",
    "Sometimes, the simplest approach is the right approach.\n",
    "\n",
    "Let's review them briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a513cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball2 = bball.set_index([\"Player\", \"Year\"])\n",
    "bball2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aad178",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball3 = bball2.T\n",
    "bball3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a640adc",
   "metadata": {},
   "source": [
    "## `stack` and `unstack`\n",
    "\n",
    "The `stack` and `unstack` methods operate directly on the index\n",
    "and/or column labels.\n",
    "\n",
    "### `stack`\n",
    "\n",
    "`stack` is used to move certain levels of the column labels into the\n",
    "index (i.e. moving from wide to long)\n",
    "\n",
    "Let's take `ball_wide` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d389236",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d130bbf",
   "metadata": {},
   "source": [
    "Suppose that we want to be able to use the `mean` method to compute the\n",
    "average value of each stat for each player, regardless of year or team.\n",
    "\n",
    "To do that, we need two column levels: one for the player and one for the variable.\n",
    "\n",
    "We can achieve this using the `stack` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8689ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_wide.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41134e5b",
   "metadata": {},
   "source": [
    "Now, we can compute the statistic we are after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats = bball_wide.stack().mean()\n",
    "player_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3975c",
   "metadata": {},
   "source": [
    "Now suppose instead of that we wanted to compute the average for each team and\n",
    "stat, averaging over years and players.\n",
    "\n",
    "We'd need to move the `Player` level down into the index so we are\n",
    "left with column levels for Team and variable.\n",
    "\n",
    "We can ask pandas do this using the `level` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_wide.stack(level=\"Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f061dc",
   "metadata": {},
   "source": [
    "Now we can compute the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4943cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_wide.stack(level=\"Player\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd8cbd",
   "metadata": {},
   "source": [
    "Notice a few features of the `stack` method:\n",
    "\n",
    "- Without any arguments, the `stack` arguments move the level of column\n",
    "  labels closest to the data (also called inner-most or bottom level of labels)\n",
    "  to become the index level closest to the data (also called the inner-most or\n",
    "  right-most level of the index). In our example, this moved `Team` down from\n",
    "  columns to the index.\n",
    "- When we do pass a level, that level of column labels is moved down to the\n",
    "  right-most level of the index and all other column labels stay in their\n",
    "  relative position.\n",
    "\n",
    "Note that we can also move multiple levels at a time in one call to `stack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_wide.stack(level=[\"Player\", \"Team\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c23edc",
   "metadata": {},
   "source": [
    "In the example above, we started with one level on the index (just the year) and\n",
    "stacked two levels to end up with a three-level index.\n",
    "\n",
    "Notice that the two new index levels went closer to the data than the existing\n",
    "level and that their order matched the order we passed in our list argument to\n",
    "`level`.\n",
    "\n",
    "### `unstack`\n",
    "\n",
    "Now suppose that we wanted to see a bar chart of each player's stats.\n",
    "\n",
    "This chart should have one \"section\" for each player and a different colored\n",
    "bar for each variable.\n",
    "\n",
    "As we'll learn in more detail in a later lecture,  we will\n",
    "need to have the player's name on the index and the variables as columns to do this.\n",
    "\n",
    "```{note}\n",
    "In general, for a DataFrame, calling the `plot` method will put the index\n",
    "on the horizontal (x) axis and make a new line/bar/etc. for each column.\n",
    "```\n",
    "\n",
    "Notice that we are close to that with the `player_stats` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea3368",
   "metadata": {},
   "source": [
    "We now need to rotate the variable level of the index up to be column layers.\n",
    "\n",
    "We use the `unstack` method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b321ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2eed9",
   "metadata": {},
   "source": [
    "And we can make our plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats.unstack().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111a24e",
   "metadata": {},
   "source": [
    "This particular visualization would be helpful if we wanted to see which stats\n",
    "for which each player is strongest.\n",
    "\n",
    "For example, we can see that Steph Curry scores far more points than he does\n",
    "rebound, but Serge Ibaka is a bit more balanced.\n",
    "\n",
    "What if we wanted to be able to compare all players for each statistic?\n",
    "\n",
    "This would be easier to do if the bars were grouped by variable, with a\n",
    "different bar for each player.\n",
    "\n",
    "To plot this, we need to have the variables on the index and the player\n",
    "name as column names.\n",
    "\n",
    "We can get this DataFrame by setting `level=\"Player\"` when calling `unstack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats.unstack(level=\"Player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats.unstack(level=\"Player\").plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0e392",
   "metadata": {},
   "source": [
    "Now we can use the chart to make a number of statements about players:\n",
    "\n",
    "- Ibaka does not get many assists, compared to Curry and Durant.\n",
    "- Steph and Kevin Durant are both high scorers.\n",
    "\n",
    "Based on the examples above, notice a few things about `unstack`:\n",
    "\n",
    "- It is the *inverse* of `stack`; `stack` will move labels down\n",
    "  from columns to index, while `unstack` moves them up from index to columns.\n",
    "- By default, `unstack` will move the level of the index closest to the data\n",
    "  and place it in the column labels closest to the data.\n",
    "\n",
    "```{note}\n",
    "Just as we can pass multiple levels to `stack`, we can also pass multiple\n",
    "levels to `unstack`.\n",
    "\n",
    "We needed to use this in our solution to the exercise below.\n",
    "```\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-shp-dir1\n",
    "See exercise 1 in the {ref}`exercise list <pd-shp-ex>`.\n",
    "````\n",
    "\n",
    "### Summary\n",
    "\n",
    "In some ways `set_index`, `reset_index`, `stack`, and `unstack`\n",
    "are the \"most fundamental\" reshaping operations...\n",
    "\n",
    "The other operations we discuss can be formulated with these\n",
    "four operations (and, in fact, some of them are exactly written as these\n",
    "operations in `pandas`'s code base).\n",
    "\n",
    "*Pro tip*: We remember stack vs unstack with a mnemonic: **U**nstack moves index\n",
    "levels **U**p\n",
    "\n",
    "## `melt`\n",
    "\n",
    "The `melt` method is used to move from wide to long form.\n",
    "\n",
    "It can be used to move all of the \"values\" stored in your DataFrame to a\n",
    "single column with all other columns being used to contain identifying\n",
    "information.\n",
    "\n",
    "```{warning}\n",
    "When you use `melt`, any index that you currently have\n",
    "will be deleted.\n",
    "```\n",
    "\n",
    "We saw used `melt` above when we constructed `bball_long`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how we made ``bball_long``\n",
    "bball.melt(id_vars=[\"Year\", \"Player\", \"Team\", \"TeamName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e941d71",
   "metadata": {},
   "source": [
    "Notice that the columns we specified as `id_vars` remained columns, but all\n",
    "other columns were put into two new columns:\n",
    "\n",
    "1. `variable`: This has dtype string and contains the former column names.\n",
    "   as values\n",
    "1. `value`: This has the former values.\n",
    "\n",
    "Using this method is an effective way to get our data in *tidy* form as noted\n",
    "above.\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-shp-dir2\n",
    "See exercise 2 in the {ref}`exercise list <pd-shp-ex>`.\n",
    "````\n",
    "\n",
    "## `pivot` and `pivot_table`\n",
    "\n",
    "The next two reshaping methods that we will use are closely related.\n",
    "\n",
    "Some of you might even already be familiar with these ideas because you\n",
    "have previously used *pivot tables* in Excel.\n",
    "\n",
    "- If so, good news. We think this is even more powerful than Excel\n",
    "  and easier to use!\n",
    "- If not, good news. You are about to learn a very powerful and user-friendly tool.\n",
    "\n",
    "We will begin with `pivot`.\n",
    "\n",
    "The `pivot` method:\n",
    "\n",
    "- Takes the unique values of one column and places them along the index.\n",
    "- Takes the unique values of another column and places them along the\n",
    "  columns.\n",
    "- Takes the values that correspond to a third column and fills in the\n",
    "  DataFrame values that correspond to that index/column pair.\n",
    "\n",
    "We'll illustrate with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77af9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head 6 excludes Ibaka -- will discuss why later\n",
    "bball.head(6).pivot(index=\"Year\", columns=\"Player\", values=\"Pts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f591fe5",
   "metadata": {},
   "source": [
    "We can replicate `pivot` using three of the fundamental operations\n",
    "from above:\n",
    "\n",
    "1. Call `set_index` with the `index` and `columns` arguments\n",
    "1. Extract the `values` column\n",
    "1. `unstack` the columns level of the new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1---------------------------------------  2---  3----------------------\n",
    "bball.head(6).set_index([\"Year\", \"Player\"])[\"Pts\"].unstack(level=\"Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993bdec",
   "metadata": {},
   "source": [
    "One important thing to be aware of is that in order for `pivot` to\n",
    "work, the index/column pairs must be *unique*!\n",
    "\n",
    "Below, we demonstrate the error that occurs when they are not unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54297573",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Ibaka shows up twice in 2016 because he was traded mid-season from\n",
    "# the Orlando Magic to the Toronto Raptors\n",
    "bball.pivot(index=\"Year\", columns=\"Player\", values=\"Pts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb1271",
   "metadata": {},
   "source": [
    "### `pivot_table`\n",
    "\n",
    "The `pivot_table` method is a generalization of `pivot`.\n",
    "\n",
    "It overcomes two limitations of `pivot`:\n",
    "\n",
    "1. It allows you to choose multiple columns for the index/columns/values\n",
    "   arguments.\n",
    "1. It allows you to deal with duplicate entries by\n",
    "   having you choose how to combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce93526",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdcbdb0",
   "metadata": {},
   "source": [
    "Notice that we can replicate the functionality of `pivot` using `pivot_table` if we pass\n",
    "the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59183761",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball.head(6).pivot_table(index=\"Year\", columns=\"Player\", values=\"Pts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc03a1",
   "metadata": {},
   "source": [
    "But we can also choose multiple columns to be used in\n",
    "index/columns/values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e46797",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball.pivot_table(index=[\"Year\", \"Team\"], columns=\"Player\", values=\"Pts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball.pivot_table(index=\"Year\", columns=[\"Player\", \"Team\"], values=\"Pts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee294725",
   "metadata": {},
   "source": [
    "AND we can deal with duplicated index/column pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcffe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This produced an error\n",
    "# bball.pivot(index=\"Year\", columns=\"Player\", values=\"Pts\")\n",
    "\n",
    "# This doesn't!\n",
    "bball_pivoted = bball.pivot_table(index=\"Year\", columns=\"Player\", values=\"Pts\")\n",
    "bball_pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34edaa4",
   "metadata": {},
   "source": [
    "`pivot_table` handles duplicate index/column pairs using an aggregation.\n",
    "\n",
    "By default, the aggregation is the mean.\n",
    "\n",
    "For example, our duplicated index/column pair is `(\"x\", 1)` and had\n",
    "associated values of 2 and 5.\n",
    "\n",
    "Notice that `bball_pivoted.loc[2016, \"Ibaka\"]` is `(15.1 + 14.2)/2 = 14.65`.\n",
    "\n",
    "We can choose how `pandas` aggregates all of the values.\n",
    "\n",
    "For example, here's how we would keep the max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff97f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball.pivot_table(index=\"Year\", columns=\"Player\", values=\"Pts\", aggfunc=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200673e",
   "metadata": {},
   "source": [
    "Maybe we wanted to count how many values there were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball.pivot_table(index=\"Year\", columns=\"Player\", values=\"Pts\", aggfunc=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18803f10",
   "metadata": {},
   "source": [
    "We can even pass multiple aggregation functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845afdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bball.pivot_table(index=\"Year\", columns=\"Player\", values=\"Pts\", aggfunc=[max, len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb446c6",
   "metadata": {},
   "source": [
    "````{admonition} Exercise\n",
    ":name: pd-shp-dir3\n",
    "See exercise 3 in the {ref}`exercise list <pd-shp-ex>`.\n",
    "````\n",
    "\n",
    "## Visualizing Reshaping\n",
    "\n",
    "Now that you have learned the basics and had a chance to experiment,\n",
    "we will use some generic data to provide a visualization of what the above\n",
    "reshape operations do.\n",
    "\n",
    "The data we will use is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# made up\n",
    "# columns A and B are \"identifiers\" while C, D, and E are variables.\n",
    "df = pd.DataFrame({\n",
    "    \"A\": [0, 0, 1, 1],\n",
    "    \"B\": \"x y x z\".split(),\n",
    "    \"C\": [1, 2, 1, 4],\n",
    "    \"D\": [10, 20, 30, 20,],\n",
    "    \"E\": [2, 1, 5, 4,]\n",
    "})\n",
    "\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6973dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index([\"A\", \"B\"])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17897431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.T\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a205c",
   "metadata": {},
   "source": [
    "### `stack` and `unstack`\n",
    "\n",
    "Below is an animation that shows how stacking works.\n",
    "\n",
    "```{figure} ../_static/stack.gif\n",
    ":alt: stack.gif\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06619505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_stack = df2.stack()\n",
    "df2_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ced1b",
   "metadata": {},
   "source": [
    "And here is an animation that shows how unstacking works.\n",
    "\n",
    "```{figure} ../_static/unstack_level0.gif\n",
    ":alt: unstack\\_level0.gif\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace9dd8",
   "metadata": {},
   "source": [
    "### `melt`\n",
    "\n",
    "As noted above, the `melt` method transforms data from wide to long in form.\n",
    "\n",
    "Here's a visualization of that operation.\n",
    "\n",
    "```{figure} ../_static/melt.gif\n",
    ":alt: melt.gif\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ef31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df.melt(id_vars=[\"A\", \"B\"])\n",
    "df_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1eb16",
   "metadata": {},
   "source": [
    "(pd-shp-ex)=\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "```{warning}\n",
    "This one is challenging\n",
    "```\n",
    "Recall the `bball_wide` DataFrame from above (repeated below to jog\n",
    "your memory).\n",
    "\n",
    "In this task, you will start from `ball` and re-recreate `bball_wide`\n",
    "by combining the operations we just learned about.\n",
    "\n",
    "There are many ways to do this, so be creative.\n",
    "\n",
    "Our solution used `set_index`, `T`, `stack`, and `unstack` in\n",
    "that order.\n",
    "\n",
    "Here are a few hints:\n",
    "\n",
    "- ```{hint}\n",
    "  Think about what columns you will need to call `set_index` on so\n",
    "  that their data ends up as labels (either in index or columns).\n",
    "  ```\n",
    "- ```{hint}\n",
    "  Leave other columns (e.g. the actual game stats) as actual columns so\n",
    "  their data can stay data during your reshaping.\n",
    "  ```\n",
    "\n",
    "Don't spend too much time on this... if you get stuck, you will find our answer [here](https://github.com/QuantEcon/lecture-datascience.myst/raw/main/lectures/_static/reshape-ex1-ans.txt).\n",
    "\n",
    "```{hint}\n",
    "You might need to add `.sort_index(axis=1)` after you are\n",
    "finished to get the columns in the same order.\n",
    "```\n",
    "\n",
    "```{hint}\n",
    "You may not end up with a `variable` header on the second\n",
    "level of column labels. This is ok.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2b8b4",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "bball_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf85336",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-shp-dir1>`)\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "- What do you think would happen if we wrote `bball.melt(id_vars=[\"Year\", \"Player\"])`\n",
    "  rather than `bball.melt(id_vars=[\"Year\", \"Player\", \"Team\", \"TeamName\"])`?\n",
    "  Were you right? Write your thoughts.\n",
    "- Read the documentation and focus on the argument `value_vars`. How\n",
    "  does `bball.melt(id_vars=[\"Year\", \"Player\"], value_vars=[\"Pts\", \"Rebound\"])`\n",
    "  differ from `bball.melt(id_vars=[\"Year\", \"Player\"])`?\n",
    "- Consider the differences between `bball.stack` and `bball.melt`.\n",
    "  Is there a way to make them generate the same output?\n",
    "  Write your thoughts.\n",
    "  - ```{hint}\n",
    "    You might need to use both `stack` and another method from\n",
    "    above\n",
    "    ```\n",
    "\n",
    "({ref}`back to text <pd-shp-dir2>`)\n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "- First, take a breath... That was a lot to take in.\n",
    "- Can you think of a reason to ever use `pivot` rather than\n",
    "  `pivot_table`? Write your thoughts.\n",
    "- Create a pivot table with column `Player` as the index, `TeamName` as the\n",
    "  columns, and `[Rebound, Assist]` as the values. What happens when you use\n",
    "  `aggfunc=[np.max, np.min, len]`? Describe how Python produced\n",
    "  each of the values in the resultant pivot table.\n",
    "\n",
    "({ref}`back to text <pd-shp-dir3>`)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "source_map": [
   10,
   29,
   34,
   104,
   110,
   120,
   125,
   129,
   137,
   153,
   158,
   161,
   175,
   177,
   186,
   188,
   192,
   195,
   205,
   207,
   211,
   213,
   228,
   230,
   256,
   258,
   264,
   266,
   270,
   272,
   290,
   294,
   296,
   349,
   353,
   356,
   396,
   399,
   408,
   411,
   418,
   425,
   438,
   440,
   445,
   447,
   452,
   456,
   458,
   462,
   469,
   484,
   486,
   490,
   492,
   496,
   498,
   513,
   528,
   533,
   536,
   546,
   550,
   553,
   561,
   565,
   567,
   579,
   583,
   586,
   630,
   633
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}