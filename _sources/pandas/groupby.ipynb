{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a785dcf6",
   "metadata": {},
   "source": [
    "# GroupBy\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- {doc}`Functions <../python_fundamentals/functions>`\n",
    "- pandas introduction {doc}`1 <intro>` and {doc}`2 <basics>`\n",
    "- {doc}`Reshape <reshape>`\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand the split-apply-combine strategy for aggregate\n",
    "  computations on groups of data\n",
    "- Be able use basic aggregation methods on `df.groupby` to compute\n",
    "  within group statistics\n",
    "- Understand how to group by multiple keys at once\n",
    "\n",
    "**Data**\n",
    "\n",
    "- Details for all delayed US domestic flights in December 2016,\n",
    "  obtained from the [Bureau of Transportation\n",
    "  Statistics](https://www.transtats.bts.gov/OT_Delay/OT_DelayCause1.asp)\n",
    "  \n",
    "```{literalinclude} ../_static/colab_light.raw\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c470031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b5830",
   "metadata": {},
   "source": [
    "## Split-Apply-Combine\n",
    "\n",
    "One powerful paradigm for analyzing data is the \"Split-Apply-Combine\"\n",
    "strategy.\n",
    "\n",
    "This strategy has three steps:\n",
    "\n",
    "1. `Split`: split the data into groups based on values in one or more columns.\n",
    "1. `Apply`: apply a function or routine to each group separately.\n",
    "1. `Combine`: combine the output of the apply step into a DataFrame,\n",
    "   using the group identifiers as the index.\n",
    "\n",
    "We will cover the main components in this lecture, but we encourage you\n",
    "to also study the [official\n",
    "documentation](https://pandas.pydata.org/pandas-docs/stable/groupby.html)\n",
    "to learn more about what is possible.\n",
    "\n",
    "To describe the concepts, we will need some data.\n",
    "\n",
    "We will begin with a simple made-up dataset to discuss the concepts and\n",
    "then work through extended example and exercises with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c64e76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B    C\n",
       "0  1  1  1.0\n",
       "1  1  1  2.0\n",
       "2  1  2  3.0\n",
       "3  2  2  NaN\n",
       "4  2  1  5.0\n",
       "5  2  1  NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.arange(1, 7, dtype=float)\n",
    "C[[3, 5]] = np.nan\n",
    "df = pd.DataFrame({\n",
    "    \"A\" : [1, 1, 1, 2, 2, 2],\n",
    "    \"B\" : [1, 1, 2, 2, 1, 1],\n",
    "    \"C\": C,\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10704ed1",
   "metadata": {},
   "source": [
    "### Simple Example\n",
    "\n",
    "To perform the *Split* step, we call the `groupby` method on our\n",
    "DataFrame.\n",
    "\n",
    "The first argument to `groupby` is a description of how we want to\n",
    "construct groups.\n",
    "\n",
    "In the most basic version, we will pass a string identifying the column\n",
    "name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d32367",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbA = df.groupby(\"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462f078",
   "metadata": {},
   "source": [
    "The `type` of variable we get back is a `DataFrameGroupBy`, which we\n",
    "will sometimes refer to as GroupBy for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3426e57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gbA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69deb075",
   "metadata": {},
   "source": [
    "Looking at the \"groups\" inside of the GroupBy object can help us\n",
    "understand what the GroupBy represents.\n",
    "\n",
    "We can do this with the `gb.get_group(group_name)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f620a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B    C\n",
       "0  1  1  1.0\n",
       "1  1  1  2.0\n",
       "2  1  2  3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbA.get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99f23b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B    C\n",
       "3  2  2  NaN\n",
       "4  2  1  5.0\n",
       "5  2  1  NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbA.get_group(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744e794",
   "metadata": {},
   "source": [
    "We can *apply* some of our favorite aggregation functions directly on the\n",
    "`GroupBy` object.\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-grp-dir1\n",
    "See exercise 1 in the {ref}`exercise list <pd-grp-ex>`.\n",
    "````\n",
    "````{admonition} Exercise\n",
    ":name: pd-grp-dir2\n",
    "See exercise 2 in the {ref}`exercise list <pd-grp-ex>`.\n",
    "````\n",
    "\n",
    "\n",
    "If we pass a list of strings to `groupby`, it will group based on\n",
    "unique combinations of values from all columns in the list.\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf5a6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.generic.DataFrameGroupBy"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbAB = df.groupby([\"A\", \"B\"])\n",
    "type(gbAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e1d7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B    C\n",
       "0  1  1  1.0\n",
       "1  1  1  2.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbAB.get_group((1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c4ab4a",
   "metadata": {},
   "source": [
    "Notice that we still have a GroupBy object, so we can apply our favorite\n",
    "aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c30903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C\n",
       "A B   \n",
       "1 1  2\n",
       "  2  1\n",
       "2 1  1\n",
       "  2  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbAB.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94114aed",
   "metadata": {},
   "source": [
    "Notice that the output is a DataFrame with two levels on the index\n",
    "and a single column `C`. (Quiz: how do we know it is a DataFrame with\n",
    "one column and not a Series?)\n",
    "\n",
    "This highlights a principle of how pandas handles the *Combine* part of\n",
    "the strategy:\n",
    "\n",
    "> The index of the combined DataFrame will be the group identifiers,\n",
    "> with one index level per group key.\n",
    "\n",
    "### Custom Aggregate Functions\n",
    "\n",
    "So far, we have been applying built-in aggregations to our GroupBy object.\n",
    "\n",
    "We can also apply custom aggregations to each group of a GroupBy in two\n",
    "steps:\n",
    "\n",
    "1. Write our custom aggregation as a Python function.\n",
    "1. Passing our function as an argument to the `.agg` method of a GroupBy.\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2edc29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_missing(df):\n",
    "    \"Return the number of missing items in each column of df\"\n",
    "    return df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8886e3e",
   "metadata": {},
   "source": [
    "We can call this function on our original DataFrame to get the number of\n",
    "missing items in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2def76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1183b68",
   "metadata": {},
   "source": [
    "We can also apply it to a GroupBy object to get the number of missing\n",
    "items in each column *for each group*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c4f6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  C\n",
       "A      \n",
       "1  0  0\n",
       "2  0  2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbA.agg(num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a145698",
   "metadata": {},
   "source": [
    "The key to keep in mind is that the function we pass to `agg` should\n",
    "take in a DataFrame (or Series) and return a Series (or single value)\n",
    "with one item per column in the original DataFrame.\n",
    "\n",
    "When the function is called, the data for each group will be passed to\n",
    "our function as a DataFrame (or Series).\n",
    "\n",
    "### Transforms: The `apply` Method\n",
    "\n",
    "As we saw in the {doc}`basics lecture <basics>`, we can apply transforms to DataFrames.\n",
    "\n",
    "We can do the same with GroupBy objects using the `.apply` method.\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0302221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B    C\n",
       "0  1  1  1.0\n",
       "1  1  1  2.0\n",
       "2  1  2  3.0\n",
       "3  2  2  NaN\n",
       "4  2  1  5.0\n",
       "5  2  1  NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64529f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallest_by_b(df):\n",
    "    return df.nsmallest(2, \"B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c31d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  B    C\n",
       "A             \n",
       "1 0  1  1  1.0\n",
       "  1  1  1  2.0\n",
       "2 4  2  1  5.0\n",
       "  5  2  1  NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbA.apply(smallest_by_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936645b",
   "metadata": {},
   "source": [
    "Notice that the return value from applying our series transform to `gbA`\n",
    "was the group key on the outer level (the `A` column) and the original\n",
    "index from `df` on the inner level.\n",
    "\n",
    "The original index came along because that was the index of the\n",
    "DataFrame returned by `smallest_by_b`.\n",
    "\n",
    "Had our function returned something other than the index from `df`,\n",
    "that would appear in the result of the call to `.apply`.\n",
    "\n",
    "````{admonition} Exercise\n",
    ":name: pd-grp-dir3\n",
    "See exercise 3 in the {ref}`exercise list <pd-grp-ex>`.\n",
    "````\n",
    "\n",
    "### `pd.Grouper`\n",
    "\n",
    "Sometimes, in order to construct the groups you want, you need to give\n",
    "pandas more information than just a column name.\n",
    "\n",
    "Some examples are:\n",
    "\n",
    "- Grouping by a column and a level of the index.\n",
    "- Grouping time series data at a particular frequency.\n",
    "\n",
    "pandas lets you do this through the `pd.Grouper` type.\n",
    "\n",
    "To see it in action, let's make a copy of `df` with `A` moved to the\n",
    "index and a `Date` column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47dad276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3353/2961039157.py:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  start=pd.datetime.today().strftime(\"%m/%d/%Y\"),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B    C       Date\n",
       "A                   \n",
       "1  1  1.0 2023-03-31\n",
       "1  1  2.0 2023-06-30\n",
       "1  2  3.0 2023-09-29\n",
       "2  2  NaN 2023-12-29\n",
       "2  1  5.0 2024-03-29\n",
       "2  1  NaN 2024-06-28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"Date\"] = pd.date_range(\n",
    "    start=pd.datetime.today().strftime(\"%m/%d/%Y\"),\n",
    "    freq=\"BQ\",\n",
    "    periods=df.shape[0]\n",
    ")\n",
    "df2 = df2.set_index(\"A\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861bdf8",
   "metadata": {},
   "source": [
    "We can group by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b7d1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            B  C\n",
       "Date            \n",
       "2023-12-31  4  3\n",
       "2024-12-31  2  1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(pd.Grouper(key=\"Date\", freq=\"A\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329f800",
   "metadata": {},
   "source": [
    "We can group by the `A` level of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831f8efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   B  C  Date\n",
       "A            \n",
       "1  3  3     3\n",
       "2  3  1     3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(pd.Grouper(level=\"A\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3dc06",
   "metadata": {},
   "source": [
    "We can combine these to group by both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54e559dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2023-12-31</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              B  C\n",
       "Date       A      \n",
       "2023-12-31 1  3  3\n",
       "           2  1  0\n",
       "2024-12-31 2  2  1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby([pd.Grouper(key=\"Date\", freq=\"A\"), pd.Grouper(level=\"A\")]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ba9c0",
   "metadata": {},
   "source": [
    "And we can combine `pd.Grouper` with a string, where the string\n",
    "denotes a column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a3adf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2023-12-31</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              C\n",
       "Date       B   \n",
       "2023-12-31 1  2\n",
       "           2  1\n",
       "2024-12-31 1  1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby([pd.Grouper(key=\"Date\", freq=\"A\"), \"B\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c29a92",
   "metadata": {},
   "source": [
    "## Case Study: Airline Delays\n",
    "\n",
    "Let's apply our new split-apply-combine skills to the airline dataset we\n",
    "saw in the {doc}`merge <merge>` lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a1fc02",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://datascience.quantecon.org/assets/data/airline_performance_dec16.csv.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m air_dec \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    722\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:363\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    362\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    364\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "url = \"https://datascience.quantecon.org/assets/data/airline_performance_dec16.csv.zip\"\n",
    "air_dec = pd.read_csv(url, parse_dates = ['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01392d",
   "metadata": {},
   "source": [
    "First, we compute the average delay in arrival time for all carriers\n",
    "each week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_delays = (\n",
    "    air_dec\n",
    "    .groupby([pd.Grouper(key=\"Date\", freq=\"W\"), \"Carrier\"])\n",
    "    [\"ArrDelay\"]               # extract one column\n",
    "    .mean()                    # take average\n",
    "    .unstack(level=\"Carrier\")  # Flip carrier up as column names\n",
    ")\n",
    "weekly_delays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347eca47",
   "metadata": {},
   "source": [
    "Let's also plot this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c39420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "axs = weekly_delays.plot.bar(\n",
    "    figsize=(10, 8), subplots=True, legend=False, sharex=True,\n",
    "    sharey=True, layout=(4, 3), grid=False\n",
    ")\n",
    "\n",
    "# tweak spacing between subplots and xaxis labels\n",
    "axs[0,0].get_figure().tight_layout()\n",
    "for ax in axs[-1, :]:\n",
    "    ax.set_xticklabels(weekly_delays.index.strftime(\"%a, %b. %d'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e59663",
   "metadata": {},
   "source": [
    "It looks like more delays occurred during the week ending Sunday\n",
    "December 18th than any other week (except for Frontier, who did *worse*\n",
    "on Christmas week).\n",
    "\n",
    "Let's see why.\n",
    "\n",
    "The `air_dec` DataFrame has information on the minutes of delay\n",
    "attributed to 5 different categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_cols = [\n",
    "    'CarrierDelay',\n",
    "    'WeatherDelay',\n",
    "    'NASDelay',\n",
    "    'SecurityDelay',\n",
    "    'LateAircraftDelay'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40dbd8a",
   "metadata": {},
   "source": [
    "Let's take a quick look at each of those delay categories for the week ending December 18, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_christmas = air_dec.loc[\n",
    "    (air_dec[\"Date\"] >= \"2016-12-12\") & (air_dec[\"Date\"] <= \"2016-12-18\")\n",
    "]\n",
    "\n",
    "# custom agg function\n",
    "def positive(df):\n",
    "    return (df > 0).sum()\n",
    "\n",
    "delay_totals = pre_christmas.groupby(\"Carrier\")[delay_cols].agg([\"sum\", \"mean\", positive])\n",
    "delay_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534f698",
   "metadata": {},
   "source": [
    "**Want**: plot total, average, and number of each type of delay by\n",
    "carrier\n",
    "\n",
    "To do this, we need to have a DataFrame with:\n",
    "\n",
    "- Delay type in index (so it is on horizontal-axis)\n",
    "- Aggregation method on *outer* most level of columns (so we can do\n",
    "  `data[\"mean\"]` to get averages)\n",
    "- Carrier name on inner level of columns\n",
    "\n",
    "Many sequences of the reshaping commands can accomplish this.\n",
    "\n",
    "We show one example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_delays = (\n",
    "    delay_totals\n",
    "    .stack()             # move aggregation method into index (with Carrier)\n",
    "    .T                   # put delay type in index and Carrier+agg in column\n",
    "    .swaplevel(axis=1)   # make agg method outer level of column label\n",
    "    .sort_index(axis=1)  # sort column labels so it prints nicely\n",
    ")\n",
    "reshaped_delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66308681",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agg in [\"mean\", \"sum\", \"positive\"]:\n",
    "    axs = reshaped_delays[agg].plot(\n",
    "        kind=\"bar\", subplots=True, layout=(4, 3), figsize=(10, 8), legend=False,\n",
    "        sharex=True, sharey=True\n",
    "    )\n",
    "    fig = axs[0, 0].get_figure()\n",
    "    fig.suptitle(agg)\n",
    "#     fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa8a1b",
   "metadata": {},
   "source": [
    "````{admonition} Exercise\n",
    ":name: pd-grp-dir4\n",
    "See exercise 4 in the {ref}`exercise list <pd-grp-ex>`.\n",
    "````\n",
    "\n",
    "Let's summarize what we did:\n",
    "\n",
    "- Computed average flight delay for each airline for each week.\n",
    "- Noticed that one week had more delays for all airlines.\n",
    "- Studied the flights in that week to determine the *cause* of the\n",
    "  delays in that week.\n",
    "\n",
    "Suppose now that we want to repeat that analysis, but at a daily\n",
    "frequency instead of weekly.\n",
    "\n",
    "We could copy/paste the code from above and change the `W` to a `D`,\n",
    "but there's a better way...\n",
    "\n",
    "Let's convert the steps above into two functions:\n",
    "\n",
    "1. Produce the set of bar charts for average delays at each frequency.\n",
    "1. Produce the second set of charts for the total, average, and number\n",
    "   of occurrences of each type of delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d534cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_delay_plot(df, freq, figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Make a bar chart of average flight delays for each carrier at\n",
    "    a given frequency.\n",
    "    \"\"\"\n",
    "    mean_delays = (\n",
    "        df\n",
    "        .groupby([pd.Grouper(key=\"Date\", freq=freq), \"Carrier\"])\n",
    "        [\"ArrDelay\"]               # extract one column\n",
    "        .mean()                    # take average\n",
    "        .unstack(level=\"Carrier\")  # Flip carrier up as column names\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    axs = mean_delays.plot.bar(\n",
    "        figsize=figsize, subplots=True, legend=False, sharex=True,\n",
    "        sharey=True, layout=(4, 3), grid=False\n",
    "    )\n",
    "\n",
    "    # tweak spacing between subplots and x-axis labels\n",
    "    axs[0, 0].get_figure().tight_layout()\n",
    "    for ax in axs[-1, :]:\n",
    "        ax.set_xticklabels(mean_delays.index.strftime(\"%a, %b. %d'\"))\n",
    "\n",
    "    # return the axes in case we want to further tweak the plot outside the function\n",
    "    return axs\n",
    "\n",
    "\n",
    "def delay_type_plot(df, start, end):\n",
    "    \"\"\"\n",
    "    Make bar charts for total minutes, average minutes, and number of\n",
    "    occurrences for each delay type, for all flights that were scheduled\n",
    "    between `start` date and `end` date\n",
    "    \"\"\"\n",
    "    sub_df = df.loc[\n",
    "        (df[\"Date\"] >= start) & (df[\"Date\"] <= end)\n",
    "    ]\n",
    "\n",
    "    def positive(df):\n",
    "        return (df > 0).sum()\n",
    "\n",
    "    aggs = sub_df.groupby(\"Carrier\")[delay_cols].agg([\"sum\", \"mean\", positive])\n",
    "\n",
    "    reshaped = aggs.stack().T.swaplevel(axis=1).sort_index(axis=1)\n",
    "\n",
    "    for agg in [\"mean\", \"sum\", \"positive\"]:\n",
    "        axs = reshaped[agg].plot(\n",
    "            kind=\"bar\", subplots=True, layout=(4, 3), figsize=(10, 8), legend=False,\n",
    "            sharex=True, sharey=True\n",
    "        )\n",
    "        fig = axs[0, 0].get_figure()\n",
    "        fig.suptitle(agg)\n",
    "#         fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87116263",
   "metadata": {},
   "source": [
    "````{admonition} Exercise\n",
    ":name: pd-grp-dir5\n",
    "See exercise 5 in the {ref}`exercise list <pd-grp-ex>`.\n",
    "````\n",
    "\n",
    "Now let's look at that plot at a daily frequency. (Note that we need the\n",
    "figure to be a bit wider in order to see the dates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_delay_plot(air_dec, \"D\", figsize=(16, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ce19f",
   "metadata": {},
   "source": [
    "As we expected given our analysis above, the longest average delays\n",
    "seemed to happen in the third week.\n",
    "\n",
    "In particular, it looks like December 17th and 18th had  on average \n",
    "higher delays than other days in December.\n",
    "\n",
    "Let's use the `delay_type_plot` function to determine the cause of the\n",
    "delays on those two days.\n",
    "\n",
    "Because our analysis is captured in a single function, we can look at\n",
    "the days together and separately without much effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both days\n",
    "delay_type_plot(air_dec, \"12-17-16\", \"12-18-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc82b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the 17th\n",
    "delay_type_plot(air_dec, \"12-17-16\", \"12-17-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the 18th\n",
    "delay_type_plot(air_dec, \"12-18-16\", \"12-18-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac774e3",
   "metadata": {},
   "source": [
    "The purpose of this exercise was to drive home the ability to *automate*\n",
    "tasks.\n",
    "\n",
    "We were able to write a pair of `functions` that allows us to easily\n",
    "repeat the exact same analysis on different subsets of the data, or\n",
    "different datasets entirely (e.g. we could do the same analysis on\n",
    "November 2016 data, with two lines of code).\n",
    "\n",
    "These principles can be applied in many settings.\n",
    "\n",
    "Keep that in mind as we work through the rest of the materials.\n",
    "\n",
    "## Exercise: Cohort Analysis using Shopify Data\n",
    "\n",
    "The code below will employ a fairly large simulated data set that has the\n",
    "properties of a order-detail report from [Shopify](https://www.shopify.com/).\n",
    "\n",
    "We'll first look at the data, and then describe the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the \"randomness\" seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "url = \"https://datascience.quantecon.org/assets/data/shopify_orders.csv.zip\"\n",
    "orders = pd.read_csv(url)\n",
    "orders.info()\n",
    "\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d5252",
   "metadata": {},
   "source": [
    "We define a customer's cohort as the month in which a customer placed\n",
    "their first order and the customer type as an indicator of whether this\n",
    "was their first order or a returning order.\n",
    "\n",
    "We now describe the *want* for the exercise, which we ask you to\n",
    "complete.\n",
    "\n",
    "**Want**: Compute the monthly total number of orders, total sales, and\n",
    "total quantity separated by customer cohort and customer type.\n",
    "\n",
    "Read that carefully one more time...\n",
    "\n",
    "### Extended Exercise\n",
    "\n",
    "Using the reshape and `groupby` tools you have learned, apply the want\n",
    "operator described above.\n",
    "\n",
    "See below for advice on how to proceed.\n",
    "\n",
    "When you are finished, you should have something that looks like this:\n",
    "\n",
    "```{figure} ../_static/groupby_cohort_analysis_exercise_output.png\n",
    ":alt: groupby\\_cohort\\_analysis\\_exercise\\_output.png\n",
    "```\n",
    "\n",
    "Two notes on the table above:\n",
    "\n",
    "Your actual output will be much bigger. This is just to give you an\n",
    ": idea of what it might look like.\n",
    "\n",
    "The numbers you produce should actually be the same as what are\n",
    ": included in this table... Index into your answer and compare what you\n",
    "  have with this table to verify your progress.\n",
    "\n",
    "\n",
    "\n",
    "Now, how to do it?\n",
    "\n",
    "There is more than one way to code this, but here are some suggested\n",
    "steps.\n",
    "\n",
    "1. Convert the `Day` column to have a `datetime` `dtype` instead\n",
    "   of object.\n",
    "    - ```{hint}\n",
    "      Use the `pd.to_datetime` function.\n",
    "      ```\n",
    "1. Add a new column that specifies the date associated with each\n",
    "   customer's `\"First-time\"` order.\n",
    "    - ```{hint}\n",
    "      You can do this with a combination of `groupby` and\n",
    "      `join`.\n",
    "      ```\n",
    "    - ```{hint}\n",
    "      `customer_type` is always one of `Returning` and `First-time`.\n",
    "      ```\n",
    "    - ```{hint}\n",
    "      Some customers don't have a `customer_type == \"First-time\"` entry. You will need to set the\n",
    "      value for these users to some date that precedes the dates in the\n",
    "      sample. After adding valid data back into `orders` DataFrame,\n",
    "      you can identify which customers don't have a `\"First-Time\"`\n",
    "      entry by checking for missing data in the new column.\n",
    "      ```\n",
    "1. You'll need to group by 3 things.\n",
    "1. You can apply one of the built-in aggregation functions to the GroupBy.\n",
    "1. After doing the aggregation, you'll need to use your reshaping skills to\n",
    "   move things to the right place in rows and columns.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "(pd-grp-ex)=\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Look closely at the output of the cells below.\n",
    "\n",
    "How did pandas compute the sum of `gbA`? What happened to the `NaN`\n",
    "entries in column `C`?\n",
    "\n",
    "Write your thoughts.\n",
    "\n",
    "```{hint}\n",
    "Try `gbA.count()` or `gbA.mean()` if you can't decide what\n",
    "happened to the `NaN`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291cbf6a",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42067d0e",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "gbA.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41830f",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-grp-dir1>`)\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "Use introspection (tab completion) to see what other aggregations are\n",
    "defined for GroupBy objects.\n",
    "\n",
    "Pick three and evaluate them in the cells below.\n",
    "\n",
    "Does the output of each of these commands have the same features as the\n",
    "output of `gbA.sum()` from above? If not, what is different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187642c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a277be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea9f91",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-grp-dir2>`)\n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "```{note} \n",
    "This exercise has a few steps:\n",
    "```\n",
    "\n",
    "1. Write a function that, given a DataFrame, computes each entry's\n",
    "deviation from the mean of its column.\n",
    "2. Apply the function to `gbA`.\n",
    "3. With your neighbor describe what the index and and columns are? Where\n",
    "are the group keys (the `A` column)?\n",
    "4. Determine the correct way to add these results back into `df` as\n",
    "new columns. \n",
    "    - ```{hint}\n",
    "      Remember the {doc}`merge<merge>` lecture.\n",
    "      ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function here\n",
    "\n",
    "\n",
    "# apply function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ccc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add output of function as new columns to df here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373edc7a",
   "metadata": {},
   "source": [
    "Note that if the group keys remained in the index as the `.apply`'s output, the merge/join step would have been complicated.\n",
    "\n",
    "({ref}`back to text <pd-grp-dir3>`)\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "Think about what is shown in the the plots above.\n",
    "\n",
    "Answer questions like:\n",
    "\n",
    "- Which type of delay was the most common?\n",
    "- Which one caused the largest average delay?\n",
    "- Does that vary by airline?\n",
    "\n",
    "Write your thoughts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f81513",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-grp-dir4>`)\n",
    "\n",
    "### Exercise 5\n",
    "\n",
    "Verify that we wrote the functions properly by setting the arguments to\n",
    "appropriate values to replicate the plots from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call mean_delay_plot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ba818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call delay_type_plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b9170",
   "metadata": {},
   "source": [
    "({ref}`back to text <pd-grp-dir5>`)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "source_map": [
   10,
   37,
   44,
   69,
   78,
   91,
   93,
   98,
   100,
   107,
   111,
   113,
   133,
   138,
   140,
   145,
   147,
   171,
   175,
   180,
   182,
   187,
   189,
   206,
   210,
   215,
   217,
   249,
   258,
   262,
   264,
   268,
   270,
   274,
   276,
   281,
   283,
   290,
   293,
   298,
   307,
   311,
   322,
   333,
   341,
   345,
   356,
   372,
   383,
   392,
   418,
   472,
   482,
   484,
   498,
   503,
   508,
   511,
   532,
   542,
   630,
   635,
   638,
   652,
   656,
   660,
   662,
   683,
   690,
   692,
   710,
   712,
   721,
   725,
   727
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}