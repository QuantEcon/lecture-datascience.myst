

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Machine Learning in Economics &#8212; QuantEcon DataScience</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/quantecon-book-theme.279dae03c5caae754d20501e3fa00bbf.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />


    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script src="../_static/quantecon-book-theme.15b0c36fffe88f468997fa7b698991d3.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-S8CBQPC844"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-S8CBQPC844');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"extensions": ["autobold.js"], "macros": {"argmax": "arg\\,max", "argmin": "arg\\,min", "col": "col"}, "processEscapes": true}, "svg": {"scale": "0.92,"}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'applications/ml_in_economics';</script>
    <link rel="canonical" href="https://datascience.quantecon.org/applications/ml_in_economics.html" />
    <link rel="shortcut icon" href="../_static/lectures-favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Social and Economic Networks" href="networks.html" />
    <link rel="prev" title="Applications" href="index.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Chase Coleman, Spencer Lyon, and Jesse Perla" />
<meta name="keywords" content="Python, QuantEcon, DataScience" />
<meta name="description" content=This website presents a series of lectures on programming, data science, and economics. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Machine Learning in Economics"/>
<meta name="twitter:description" content="This website presents a series of lectures on programming, data science, and economics.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Machine Learning in Economics" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://datascience.quantecon.org/applications/ml_in_economics.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a series of lectures on programming, data science, and economics." />
<meta property="og:site_name" content="QuantEcon DataScience" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=applications/ml_in_economics>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction-policy">Prediction Policy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-nuisance-functions">Estimation of Nuisance Functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partially-linear-regression">Partially Linear Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#application-gender-wage-gap">Application: Gender Wage Gap</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#equal-pay-for-equal-work">Equal Pay for Equal Work?</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-applications">Other Applications</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#heterogeneous-effects">Heterogeneous Effects</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="../_static/datascience-logo.png" class="logo" alt="logo"></a>
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="../index.html">QuantEcon DataScience</a></p>

                        <p class="qe-page__header-subheading">Machine Learning in Economics</p>

                    </div>

                    <p class="qe-page__header-authors">Chase Coleman, Spencer Lyon, and Jesse Perla</p>

                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <section class="tex2jax_ignore mathjax_ignore" id="machine-learning-in-economics">
<h1>Machine Learning in Economics<a class="headerlink" href="#machine-learning-in-economics" title="Permalink to this heading">#</a></h1>
<p><strong>Author</strong></p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://economics.ubc.ca/faculty-and-staff/paul-schrimpf/">Paul Schrimpf <em>UBC</em></a></p></li>
</ul>
</div></blockquote>
<p><strong>Prerequisites</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../tools/regression.html"><span class="doc">Regression</span></a></p></li>
</ul>
<p><strong>Outcomes</strong></p>
<ul class="simple">
<li><p>Understand how economists use machine learning in
academic research</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uncomment following line to install on colab</span>
<span class="c1">#! pip install fiona geopandas xgboost gensim folium pyLDAvis descartes</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="c1">#plt.style.use(&#39;tableau-colorblind10&#39;)</span>
<span class="c1">#plt.style.use(&#39;Solarize_Light2&#39;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;bmh&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">#</a></h2>
<p>Machine learning is increasingly being utilized in economic
research. Here, we discuss three main ways that economists are
currently using machine learning methods.</p>
</section>
<section id="prediction-policy">
<h2>Prediction Policy<a class="headerlink" href="#prediction-policy" title="Permalink to this heading">#</a></h2>
<p>Most empirical economic research focuses on questions of
causality. However, machine learning methods can actually be used
in economic research or policy making when the goal is prediction.</p>
<p><span id="id1">[<a class="reference internal" href="#id13" title="Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. Prediction policy problems. American Economic Review, 105(5):491-95, May 2015. URL: http://www.aeaweb.org/articles?id=10.1257/aer.p20151023, doi:10.1257/aer.p20151023.">mlKLMO15</a>]</span> is a short paper which makes this point.</p>
<blockquote>
<div><p>Consider two toy examples. One policymaker facing a drought must
decide whether to invest in a rain dance to increase the chance
of rain.  Another seeing clouds must decide whether to take an
umbrella to work to avoid getting wet on the way home. Both
decisions could benefit from an empirical study of rain. But each
has differ-ent requirements of the estimator. One requires
causality: Do rain dances cause rain? The other does not, needing
only prediction: Is the chance of rain high enough to merit an
umbrella?  We often focus on rain dance–like policy problems. But
there are also many umbrella-like policy problems.  Not only are
these prediction problems neglected, machine learning can help
us solve them more effectively.  <span id="id2">[<a class="reference internal" href="#id13" title="Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. Prediction policy problems. American Economic Review, 105(5):491-95, May 2015. URL: http://www.aeaweb.org/articles?id=10.1257/aer.p20151023, doi:10.1257/aer.p20151023.">mlKLMO15</a>]</span>.</p>
</div></blockquote>
<p>One of their examples is the allocation of joint replacements for
osteoarthritis in elderly patients. Joint replacements are costly,
both monetarily and in terms of potentially painful recovery from
surgery. Joint replacements may not be worthwhile for patients who do
not live long enough afterward to enjoy the
benefits. <span id="id3">[<a class="reference internal" href="#id13" title="Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. Prediction policy problems. American Economic Review, 105(5):491-95, May 2015. URL: http://www.aeaweb.org/articles?id=10.1257/aer.p20151023, doi:10.1257/aer.p20151023.">mlKLMO15</a>]</span> uses machine learning methods to
predict mortality and argues that avoiding joint replacements
for people with the highest predicted mortality risk could lead to
sizable benefits.</p>
<p>Other situations where improved prediction could improve economic
policy include:</p>
<ul class="simple">
<li><p>Targeting safety or health inspections.</p></li>
<li><p>Predicting highest risk youth for targeting interventions.</p></li>
<li><p>Improved risk scoring in insurance markets to reduce adverse
selection.</p></li>
<li><p>Improved credit scoring to better allocate credit.</p></li>
<li><p>Predicting the risk someone accused of a crime does not show up for
trial to help decide whether to offer bail <span id="id4">[<a class="reference internal" href="#id12" title="Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. Human Decisions and Machine Predictions*. The Quarterly Journal of Economics, 133(1):237-293, 08 2017. URL: https://dx.doi.org/10.1093/qje/qjx032, arXiv:http://oup.prod.sis.lan/qje/article-pdf/133/1/237/24246094/qjx032.pdf, doi:10.1093/qje/qjx032.">mlKLL+17</a>]</span>.</p></li>
</ul>
<p>We investigated one such prediction policy problem in
<a class="reference internal" href="recidivism.html"><span class="doc">recidivism</span></a>.</p>
</section>
<section id="estimation-of-nuisance-functions">
<h2>Estimation of Nuisance Functions<a class="headerlink" href="#estimation-of-nuisance-functions" title="Permalink to this heading">#</a></h2>
<p>Most empirical economic studies are interested in a single low
dimensional parameter, but determining that parameter may require estimating additional
“nuisance” parameters to estimate this coefficient consistently and avoid omitted variables
bias. However, the choice of which other variables to include and
their functional forms is often somewhat arbitrary.
One promising idea is to use machine learning methods to let the data
decide what control variables to include and how. Care must be
taken when doing so, though, because machine learning’s flexibility and complexity
– what make it so good at prediction – also pose
challenges for inference.</p>
<section id="partially-linear-regression">
<h3>Partially Linear Regression<a class="headerlink" href="#partially-linear-regression" title="Permalink to this heading">#</a></h3>
<p>To be more concrete, consider a regression model.  We have some
regressor of interest, <span class="math notranslate nohighlight">\(d\)</span>, and we want to estimate the effect of <span class="math notranslate nohighlight">\(d\)</span>
on <span class="math notranslate nohighlight">\(y\)</span>. We have a rich enough set of controls <span class="math notranslate nohighlight">\(x\)</span> that we are willing to
believe that <span class="math notranslate nohighlight">\(E[\epsilon|d,x] = 0\)</span> . <span class="math notranslate nohighlight">\(d_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> are scalars, while
<span class="math notranslate nohighlight">\(x_i\)</span> is a vector. We are not interested in <span class="math notranslate nohighlight">\(x\)</span> per se, but we need to
include it to avoid omitted variable bias. Suppose the true model
generating the data is:</p>
<div class="math notranslate nohighlight">
\[
y = \theta d + f(x) + \epsilon
\]</div>
<p>where <span class="math notranslate nohighlight">\(f(x)\)</span> is some unknown function. This is called a
partially linear model: linear in <span class="math notranslate nohighlight">\(d\)</span>, but not in
<span class="math notranslate nohighlight">\(x\)</span> .</p>
<p>A typical applied econometric approach for this model would
be to choose some transform of <span class="math notranslate nohighlight">\(x\)</span>, say <span class="math notranslate nohighlight">\(X = T(x)\)</span>, where <span class="math notranslate nohighlight">\(X\)</span>
could be some subset of <span class="math notranslate nohighlight">\(x\)</span> , perhaps along with interactions, powers, and
so on. Then, we estimate a linear regression,</p>
<div class="math notranslate nohighlight">
\[
y = \theta d + X'\beta + e
\]</div>
<p>and then perhaps also report results for a handful of different
choices of <span class="math notranslate nohighlight">\(T(x)\)</span> .</p>
<p>Some downsides to the typical applied econometric practice
include:</p>
<ul class="simple">
<li><p>The choice of <span class="math notranslate nohighlight">\(T\)</span> is arbitrary, which opens the door to specification
searching and p-hacking.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(x\)</span> is high dimensional and <span class="math notranslate nohighlight">\(X\)</span> is low dimensional, a poor
choice will lead to omitted variable bias. Even if <span class="math notranslate nohighlight">\(x\)</span> is low
dimensional,  omitted variable bias occurs if <span class="math notranslate nohighlight">\(f(x)\)</span> is poorly approximated by <span class="math notranslate nohighlight">\(X'\beta\)</span>.</p></li>
</ul>
<p>In some sense, machine learning can be thought of as a way to
choose <span class="math notranslate nohighlight">\(T\)</span> in an automated and data-driven way. Choosing which machine learning method
to use and tuning parameters specifically for that method are still potentially arbitrary
decisions, but these decisions may have less impact.</p>
<p>Economic researchers typically don’t just want an estimate of
<span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. Instead, they want to know that
<span class="math notranslate nohighlight">\(\hat{\theta}\)</span> has good statistical properties (it should at
least be consistent), and they want some way to quantify how uncertain is
<span class="math notranslate nohighlight">\(\hat{\theta}\)</span> (i.e. they want a standard error). The complexity
of machine learning methods makes their statistical properties
difficult to understand. If we want <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> to have
known and good statistical properties, we must make sure we use machine
learning methods correctly.  A procedure to estimate
<span class="math notranslate nohighlight">\(\theta\)</span> in the partially linear model is as follows:</p>
<ol class="arabic simple">
<li><p>Predict <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(d\)</span> from <span class="math notranslate nohighlight">\(x\)</span> using any machine
learning method with “cross-fitting”.</p>
<ul class="simple">
<li><p>Partition the data in <span class="math notranslate nohighlight">\(k\)</span> subsets.</p></li>
<li><p>For the <span class="math notranslate nohighlight">\(j\)</span> th subset, train models to predict <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(d\)</span>
using the other <span class="math notranslate nohighlight">\(k-1\)</span> subsets. Denote the predictions from
these models as <span class="math notranslate nohighlight">\(p^y_{-j}(x)\)</span> and  <span class="math notranslate nohighlight">\(p^d_{-j}(x)\)</span>.</p></li>
<li><p>For <span class="math notranslate nohighlight">\(y_i\)</span> in the <span class="math notranslate nohighlight">\(j\)</span> -th subset use the other
<span class="math notranslate nohighlight">\(k-1\)</span> subsets to predict <span class="math notranslate nohighlight">\(\hat{y}_i = p^y_{-j(i)}(x_i)\)</span></p></li>
</ul>
</li>
<li><p>Partial out <span class="math notranslate nohighlight">\(x\)</span> : let <span class="math notranslate nohighlight">\(\tilde{y}_i = y_i - \hat{y}_i\)</span>
and <span class="math notranslate nohighlight">\(\tilde{d}_i = d_i - \hat{d}_i\)</span>.</p></li>
<li><p>Regress <span class="math notranslate nohighlight">\(\tilde{y}_i\)</span> on <span class="math notranslate nohighlight">\(\tilde{d}_i\)</span>, let
<span class="math notranslate nohighlight">\(\hat{\theta}\)</span> be the estimated coefficient for
<span class="math notranslate nohighlight">\(\tilde{d}_i\)</span> . <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is consistent,
asymptotically normal, and has the usual standard error (i.e. the
standard error given by statsmodels is correct).</p></li>
</ol>
<p>Some remarks:</p>
<ul class="simple">
<li><p>This procedure gives a <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> that has the same
asymptotic distribution as what we would get if we knew the true
<span class="math notranslate nohighlight">\(f(x)\)</span> . In statistics, we call this an oracle property,
because it is as if an all knowing oracle told us <span class="math notranslate nohighlight">\(f(x)\)</span>.</p></li>
<li><p>This procedure requires some technical conditions on the data-generating
process and machine learning estimator, but we will not worry about them here. See
<span id="id5">[<a class="reference internal" href="#id14" title="Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1):C1-C68, 2018. URL: https://onlinelibrary.wiley.com/doi/abs/10.1111/ectj.12097, arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097, doi:10.1111/ectj.12097.">mlCCD+18</a>]</span> for details.</p></li>
</ul>
<p>Here is code implementing the above idea.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">import</span> <span class="nn">statsmodels</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="k">def</span> <span class="nf">partial_linear</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">yestimator</span><span class="p">,</span> <span class="n">destimator</span><span class="p">,</span> <span class="n">folds</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate the partially linear model y = d*C + f(x) + e</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : array_like</span>
<span class="sd">        vector of outcomes</span>
<span class="sd">    d : array_like</span>
<span class="sd">        vector or matrix of regressors of interest</span>
<span class="sd">    X : array_like</span>
<span class="sd">        matrix of controls</span>
<span class="sd">    mlestimate : Estimator object for partialling out X. Must have ‘fit’</span>
<span class="sd">        and ‘predict’ methods.</span>
<span class="sd">    folds : int</span>
<span class="sd">        Number of folds for cross-fitting</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ols : statsmodels regression results containing estimate of coefficient on d.</span>
<span class="sd">    yhat : cross-fitted predictions of y</span>
<span class="sd">    dhat : cross-fitted predictions of d</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># we want predicted probabilities if y or d is discrete</span>
    <span class="n">ymethod</span> <span class="o">=</span> <span class="s2">&quot;predict&quot;</span> <span class="k">if</span> <span class="kc">False</span><span class="o">==</span><span class="nb">getattr</span><span class="p">(</span><span class="n">yestimator</span><span class="p">,</span> <span class="s2">&quot;predict_proba&quot;</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;predict_proba&quot;</span>
    <span class="n">dmethod</span> <span class="o">=</span> <span class="s2">&quot;predict&quot;</span> <span class="k">if</span> <span class="kc">False</span><span class="o">==</span><span class="nb">getattr</span><span class="p">(</span><span class="n">destimator</span><span class="p">,</span> <span class="s2">&quot;predict_proba&quot;</span><span class="p">,</span><span class="kc">False</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;predict_proba&quot;</span>
    <span class="c1"># get the predictions</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">yestimator</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="n">ymethod</span><span class="p">)</span>
    <span class="n">dhat</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">destimator</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">d</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="n">dmethod</span><span class="p">)</span>
    <span class="n">ey</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span>
    <span class="n">ed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="n">dhat</span><span class="p">)</span>
    <span class="n">ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">regression</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">ey</span><span class="p">,</span><span class="n">ed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">&#39;HC0&#39;</span><span class="p">)</span>

    <span class="k">return</span><span class="p">(</span><span class="n">ols</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">dhat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="application-gender-wage-gap">
<h3>Application: Gender Wage Gap<a class="headerlink" href="#application-gender-wage-gap" title="Permalink to this heading">#</a></h3>
<p>Okay, enough theory. Let’s look at an application. Policy makers have
long been concerned with the gender wage gap. We will examine the
gender wage gap using data from the 2018 Current Population Survey (CPS) in
the US. In particular, we will use the version of the <a class="reference external" href="https://www.nber.org/cps/">CPS provided by
the NBER</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">from</span> <span class="nn">statsmodels.iolib.summary2</span> <span class="kn">import</span> <span class="n">summary_col</span>
<span class="c1"># Download CPS data</span>
<span class="n">cpsall</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_stata</span><span class="p">(</span><span class="s2">&quot;https://www.nber.org/morg/annual/morg18.dta&quot;</span><span class="p">)</span>

<span class="c1"># take subset of data just to reduce computation time</span>
<span class="n">cps</span> <span class="o">=</span> <span class="n">cpsall</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">30000</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">cps</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hhid</th>
      <th>intmonth</th>
      <th>hurespli</th>
      <th>hrhtype</th>
      <th>minsamp</th>
      <th>hrlonglk</th>
      <th>hrsample</th>
      <th>hrhhid2</th>
      <th>serial</th>
      <th>hhnum</th>
      <th>...</th>
      <th>ym_file</th>
      <th>ym</th>
      <th>ch02</th>
      <th>ch35</th>
      <th>ch613</th>
      <th>ch1417</th>
      <th>ch05</th>
      <th>ihigrdc</th>
      <th>docc00</th>
      <th>dind02</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>103153</th>
      <td>150909100105603</td>
      <td>May</td>
      <td>1.0</td>
      <td>Civilian male primary individual</td>
      <td>MIS 4</td>
      <td>MIS 2-4 Or MIS 6-8 (link To</td>
      <td>0801</td>
      <td>08011</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>700</td>
      <td>697</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>Business and financial operations occupations</td>
      <td>Professional and Technical services</td>
    </tr>
    <tr>
      <th>76648</th>
      <td>505760912076673</td>
      <td>March</td>
      <td>1.0</td>
      <td>Husband/wife primary fam (neither in Armed For...</td>
      <td>MIS 4</td>
      <td>MIS 2-4 Or MIS 6-8 (link To</td>
      <td>0811</td>
      <td>08111</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>698</td>
      <td>695</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>12.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>51433</th>
      <td>481462012350753</td>
      <td>February</td>
      <td>1.0</td>
      <td>Husband/wife primary fam (neither in Armed For...</td>
      <td>MIS 4</td>
      <td>MIS 2-4 Or MIS 6-8 (link To</td>
      <td>0701</td>
      <td>07011</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>697</td>
      <td>694</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>Management occupations</td>
      <td>Agriculture</td>
    </tr>
    <tr>
      <th>75550</th>
      <td>106518879410166</td>
      <td>March</td>
      <td>2.0</td>
      <td>Husband/wife primary fam (neither in Armed For...</td>
      <td>MIS 8</td>
      <td>MIS 2-4 Or MIS 6-8 (link To</td>
      <td>0611</td>
      <td>06111</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>698</td>
      <td>683</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>11.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>284643</th>
      <td>466023401171104</td>
      <td>December</td>
      <td>1.0</td>
      <td>Husband/wife primary fam (neither in Armed For...</td>
      <td>MIS 4</td>
      <td>MIS 2-4 Or MIS 6-8 (link To</td>
      <td>0901</td>
      <td>09011</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>707</td>
      <td>704</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>13.0</td>
      <td>Management occupations</td>
      <td>Membership associations and organizations</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 98 columns</p>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hurespli</th>
      <th>hhnum</th>
      <th>cbsafips</th>
      <th>county</th>
      <th>centcity</th>
      <th>smsastat</th>
      <th>icntcity</th>
      <th>smsa04</th>
      <th>relref95</th>
      <th>age</th>
      <th>...</th>
      <th>recnum</th>
      <th>year</th>
      <th>ym_file</th>
      <th>ym</th>
      <th>ch02</th>
      <th>ch35</th>
      <th>ch613</th>
      <th>ch1417</th>
      <th>ch05</th>
      <th>ihigrdc</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>29997.000000</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>24701.000000</td>
      <td>29689.000000</td>
      <td>3845.000000</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>...</td>
      <td>30000.00000</td>
      <td>30000.0</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>30000.00000</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>30000.000000</td>
      <td>21463.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.314898</td>
      <td>1.052733</td>
      <td>22812.328667</td>
      <td>25.752033</td>
      <td>1.926157</td>
      <td>1.188150</td>
      <td>1.377373</td>
      <td>3.687667</td>
      <td>3.200333</td>
      <td>47.856967</td>
      <td>...</td>
      <td>217052.62500</td>
      <td>2018.0</td>
      <td>701.467433</td>
      <td>692.357833</td>
      <td>0.06040</td>
      <td>0.065333</td>
      <td>0.143033</td>
      <td>0.086467</td>
      <td>0.105033</td>
      <td>12.355938</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.683163</td>
      <td>0.245943</td>
      <td>16494.302775</td>
      <td>62.862911</td>
      <td>0.721596</td>
      <td>0.390839</td>
      <td>0.946464</td>
      <td>2.592477</td>
      <td>3.291772</td>
      <td>18.757968</td>
      <td>...</td>
      <td>125652.34375</td>
      <td>0.0</td>
      <td>3.467921</td>
      <td>6.970577</td>
      <td>0.23823</td>
      <td>0.247117</td>
      <td>0.350113</td>
      <td>0.281057</td>
      <td>0.306601</td>
      <td>2.478719</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>16.000000</td>
      <td>...</td>
      <td>19.00000</td>
      <td>2018.0</td>
      <td>696.000000</td>
      <td>681.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>32.000000</td>
      <td>...</td>
      <td>108185.25000</td>
      <td>2018.0</td>
      <td>698.000000</td>
      <td>686.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>12.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>25420.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>2.000000</td>
      <td>48.000000</td>
      <td>...</td>
      <td>217388.50000</td>
      <td>2018.0</td>
      <td>701.000000</td>
      <td>692.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>12.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>37900.000000</td>
      <td>29.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>6.000000</td>
      <td>3.000000</td>
      <td>63.000000</td>
      <td>...</td>
      <td>325915.00000</td>
      <td>2018.0</td>
      <td>704.000000</td>
      <td>698.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>11.000000</td>
      <td>8.000000</td>
      <td>49740.000000</td>
      <td>810.000000</td>
      <td>3.000000</td>
      <td>2.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
      <td>18.000000</td>
      <td>85.000000</td>
      <td>...</td>
      <td>434279.00000</td>
      <td>2018.0</td>
      <td>707.000000</td>
      <td>704.000000</td>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>18.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 62 columns</p>
</div></div></div>
</div>
<p>The variable “earnwke” records weekly earnings. Two
variables detail the hours of work. “uhours” is usual hours worked per
week, and “hourslw” is hours worked last week. We will try using each
measure of hours to construct the wage.  Let’s estimate the
unconditional gender earnings and wage gaps.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cps</span><span class="p">[</span><span class="s2">&quot;female&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">sex</span><span class="o">==</span><span class="mi">2</span><span class="p">)</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_earn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">earnwke</span><span class="p">)</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_earn&quot;</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">log_earn</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_uhours&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">uhourse</span><span class="p">)</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_uhours&quot;</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">log_uhours</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_hourslw&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">hourslw</span><span class="p">)</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_hourslw&quot;</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">cps</span><span class="o">.</span><span class="n">log_hourslw</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_wageu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cps</span><span class="o">.</span><span class="n">log_earn</span> <span class="o">-</span> <span class="n">cps</span><span class="o">.</span><span class="n">log_uhours</span>
<span class="n">cps</span><span class="p">[</span><span class="s2">&quot;log_wagelw&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cps</span><span class="o">.</span><span class="n">log_earn</span> <span class="o">-</span> <span class="n">cps</span><span class="o">.</span><span class="n">log_hourslw</span>


<span class="n">lm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">lm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;log_earn ~ female&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">cps</span><span class="p">,</span>
                  <span class="n">missing</span><span class="o">=</span><span class="s2">&quot;drop&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">&#39;HC0&#39;</span><span class="p">))</span>
<span class="n">lm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;log_wageu ~ female&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">cps</span><span class="p">,</span>
                   <span class="n">missing</span><span class="o">=</span><span class="s2">&quot;drop&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">&#39;HC0&#39;</span><span class="p">))</span>
<span class="n">lm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;log_wagelw ~ female&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">cps</span><span class="p">,</span>
                  <span class="n">missing</span><span class="o">=</span><span class="s2">&quot;drop&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">&#39;HC0&#39;</span><span class="p">))</span>
<span class="n">lm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;log_earn ~ female + log_hourslw + log_uhours&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">cps</span><span class="p">,</span>
                  <span class="n">missing</span><span class="o">=</span><span class="s2">&quot;drop&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cov_type</span><span class="o">=</span><span class="s1">&#39;HC0&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
/tmp/ipykernel_2606/3831816786.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  cps[&quot;log_earn&quot;][np.isinf(cps.log_earn)] = np.nan
/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
/usr/share/miniconda3/envs/lecture-datascience/lib/python3.9/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
/tmp/ipykernel_2606/3831816786.py:5: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  cps[&quot;log_uhours&quot;][np.isinf(cps.log_uhours)] = np.nan
/tmp/ipykernel_2606/3831816786.py:7: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  cps[&quot;log_hourslw&quot;][np.isinf(cps.log_hourslw)] = np.nan
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_col</span><span class="p">(</span><span class="n">lm</span><span class="p">,</span> <span class="n">stars</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
         <td></td>        <th>log_earn I</th> <th>log_wageu I</th> <th>log_wagelw I</th> <th>log_earn II</th>
</tr>
<tr>
  <th>Intercept</th>       <td>6.7473***</td>  <td>3.0970***</td>    <td>3.1056***</td>   <td>1.8014***</td> 
</tr>
<tr>
  <th></th>                <td>(0.0088)</td>   <td>(0.0072)</td>     <td>(0.0078)</td>    <td>(0.0933)</td>  
</tr>
<tr>
  <th>R-squared</th>        <td>0.0338</td>     <td>0.0179</td>       <td>0.0149</td>      <td>0.4139</td>   
</tr>
<tr>
  <th>R-squared Adj.</th>   <td>0.0337</td>     <td>0.0179</td>       <td>0.0148</td>      <td>0.4137</td>   
</tr>
<tr>
  <th>female[T.True]</th> <td>-0.3004***</td> <td>-0.1695***</td>   <td>-0.1707***</td>  <td>-0.1258***</td> 
</tr>
<tr>
  <th></th>                <td>(0.0127)</td>   <td>(0.0102)</td>     <td>(0.0112)</td>    <td>(0.0105)</td>  
</tr>
<tr>
  <th>log_hourslw</th>         <td></td>           <td></td>             <td></td>        <td>0.0907***</td> 
</tr>
<tr>
  <th></th>                    <td></td>           <td></td>             <td></td>        <td>(0.0285)</td>  
</tr>
<tr>
  <th>log_uhours</th>          <td></td>           <td></td>             <td></td>        <td>1.2631***</td> 
</tr>
<tr>
  <th></th>                    <td></td>           <td></td>             <td></td>        <td>(0.0431)</td>  
</tr>
</table></div></div>
</div>
<p>The unconditional gender gap in log earnings is about -0.3. Women earn
about 30% less than men. The unconditional gender wage gap is about
18%. The last column gives the gender earnings gap conditional on
hours. This could differ from the wage gap if, for example, full time
workers are paid higher wages than part-time. Some evidence
has suggested this, and the gender earnings gap conditional on hours is about
15%.</p>
<section id="equal-pay-for-equal-work">
<h4>Equal Pay for Equal Work?<a class="headerlink" href="#equal-pay-for-equal-work" title="Permalink to this heading">#</a></h4>
<p>A common slogan is equal pay for equal work. One way to interpret this
is that for employees with similar worker and job characteristics, no gender wage gap should exist.</p>
<p>Eliminating this wage gap across similar worker and job characteristics is one necessary
(though insufficient) condition for equality. Some of the differences (like hours in the 4th column of the above table)
might actually be a result of societal norms and/or
discrimination, so we don’t want to overgeneralize.</p>
<p>Nonetheless, let’s examine whether there is a gender wage gap
conditional on all worker and job characteristics. We want to ensure
that we control for those characteristics as flexibly as
possible, so we will use the partially linear model described above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">dmatrices</span>
<span class="c1"># Prepare data</span>
<span class="n">fmla</span>  <span class="o">=</span> <span class="s2">&quot;log_earn + female ~ log_uhours + log_hourslw + age + I(age**2) + C(race) + C(cbsafips) + C(smsastat) + C(grade92) + C(unionmme) + C(unioncov) + C(ind02) + C(occ2012)&quot;</span>
<span class="n">yd</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="n">fmla</span><span class="p">,</span><span class="n">cps</span><span class="p">)</span>
<span class="n">female</span> <span class="o">=</span> <span class="n">yd</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">logearn</span> <span class="o">=</span> <span class="n">yd</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>The choice of regularization parameter is somewhat
tricky. Cross-validation is a good way to choose the best
regularization parameter when our goal is prediction. However,
our goal here is not prediction. Instead, we want to get a well-behaved
estimate of the gender wage gap. To achieve this, we generally need a
smaller regularization parameter than what would minimize
MSE. The following code picks such a regularization parameter. Note
however, that the details of this code might not meet the technical
theoretical conditions needed for our ultimate estimate of the gender
wage gap to be consistent and asymptotically normal. The R package,
“HDM” <span id="id6">[<a class="reference internal" href="#id21" title="Victor Chernozhukov, Chris Hansen, and Martin Spindler. hdm: high-dimensional metrics. R Journal, 8(2):185-199, 2016. URL: https://journal.r-project.org/archive/2016/RJ-2016-040/index.html.">mlCHS16</a>]</span> , chooses the regularization parameter in way that
is known to be correct.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># select regularization parameter</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="mi">25</span><span class="p">))</span>
<span class="n">lassoy</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">logearn</span><span class="p">)</span>
<span class="n">lassod</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">female</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plotlassocv</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">alphas</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">alphas_</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">mse_path_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">mse_path_</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span><span class="n">mse</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">mse</span> <span class="o">+</span> <span class="n">std_error</span><span class="p">,</span> <span class="n">mse</span> <span class="o">-</span> <span class="n">std_error</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;MSE +/- std error&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">alphas</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alphas</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">plotlassocv</span><span class="p">(</span><span class="n">lassoy</span><span class="p">,</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MSE for log(earn)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">plotlassocv</span><span class="p">(</span><span class="n">lassod</span><span class="p">,</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MSE for female&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># there are theoretical reasons to choose a smaller regularization</span>
<span class="c1"># than the one that minimizes cv. BUT THIS WAY OF CHOOSING IS ARBITRARY AND MIGHT BE WRONG</span>
<span class="k">def</span> <span class="nf">pickalpha</span><span class="p">(</span><span class="n">lassocv</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">imin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">lassocv</span><span class="o">.</span><span class="n">mse_path_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">msemin</span> <span class="o">=</span> <span class="n">lassocv</span><span class="o">.</span><span class="n">mse_path_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="n">imin</span><span class="p">]</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">lassocv</span><span class="o">.</span><span class="n">mse_path_</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="n">imin</span><span class="p">]</span>
    <span class="n">alpha</span><span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="n">alpha</span> <span class="k">for</span> <span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">lassocv</span><span class="o">.</span><span class="n">alphas_</span><span class="p">,</span> <span class="n">lassocv</span><span class="o">.</span><span class="n">mse_path_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="n">mse</span><span class="o">&lt;</span><span class="n">msemin</span><span class="o">+</span><span class="n">se</span><span class="p">])</span>
    <span class="k">return</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

<span class="n">alphay</span> <span class="o">=</span> <span class="n">pickalpha</span><span class="p">(</span><span class="n">lassoy</span><span class="p">)</span>
<span class="n">alphad</span> <span class="o">=</span> <span class="n">pickalpha</span><span class="p">(</span><span class="n">lassod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4d94f79d70657b2dfb55b94df7d89fd44e4cbae6ba13fd64bd3e49f42deea3c7.png" src="../_images/4d94f79d70657b2dfb55b94df7d89fd44e4cbae6ba13fd64bd3e49f42deea3c7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># show results</span>
<span class="n">pl_lasso</span> <span class="o">=</span> <span class="n">partial_linear</span><span class="p">(</span><span class="n">logearn</span><span class="p">,</span> <span class="n">female</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span>
                          <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">lassoy</span><span class="o">.</span><span class="n">alpha_</span><span class="p">),</span>
                          <span class="n">linear_model</span><span class="o">.</span><span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">lassod</span><span class="o">.</span><span class="n">alpha_</span><span class="p">))</span>
<span class="n">pl_lasso</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.009</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.009</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   107.2</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 20 May 2024</td> <th>  Prob (F-statistic):</th>          <td>4.91e-25</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>16:45:28</td>     <th>  Log-Likelihood:    </th>          <td> -9718.3</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td> 13052</td>      <th>  AIC:               </th>          <td>1.944e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 13051</td>      <th>  BIC:               </th>          <td>1.945e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>              <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>x1</th> <td>   -0.1160</td> <td>    0.011</td> <td>  -10.356</td> <td> 0.000</td> <td>   -0.138</td> <td>   -0.094</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>6939.182</td> <th>  Durbin-Watson:     </th>  <td>   1.959</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>410073.398</td>
</tr>
<tr>
  <th>Skew:</th>           <td>-1.777</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> 
</tr>
<tr>
  <th>Kurtosis:</th>       <td>30.229</td>  <th>  Cond. No.          </th>  <td>    1.00</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors are heteroscedasticity robust (HC0)</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="c1"># Visualize predictions</span>
<span class="k">def</span> <span class="nf">plotpredictions</span><span class="p">(</span><span class="n">pl</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;logearn&quot;</span><span class="p">:</span><span class="n">logearn</span><span class="p">,</span>
                       <span class="s2">&quot;predicted&quot;</span><span class="p">:</span><span class="n">pl</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                       <span class="s2">&quot;female&quot;</span><span class="p">:</span><span class="n">female</span><span class="p">,</span>
                       <span class="s2">&quot;P(female|x)&quot;</span><span class="p">:</span><span class="n">pl</span><span class="p">[</span><span class="mi">2</span><span class="p">]})</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logearn&quot;</span><span class="p">,</span><span class="s2">&quot;predicted&quot;</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;female&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Observed and predicted log(earnings)&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">logearn</span><span class="o">-</span><span class="n">df</span><span class="o">.</span><span class="n">predicted</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">female</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Prediction Errors&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">pl</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">female</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">hist</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">kde</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;shade&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;linewidth&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                 <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Male&quot;</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">pl</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">female</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span> <span class="n">hist</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">kde</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;shade&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;linewidth&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
                 <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Female&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;P(female|x)&#39;</span><span class="p">)</span>
<span class="n">plotpredictions</span><span class="p">(</span><span class="n">pl_lasso</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2606/3039950914.py:16: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(pl[2][female==0], hist = True, kde = False,
/tmp/ipykernel_2606/3039950914.py:19: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(pl[2][female==1], hist = True, kde = False,
</pre></div>
</div>
<img alt="../_images/429c3bc6df0aa9f5ef344c3c85da22d8995094a641af85c8acb714e44936c073.png" src="../_images/429c3bc6df0aa9f5ef344c3c85da22d8995094a641af85c8acb714e44936c073.png" />
<img alt="../_images/d15e0c341d8d00005c4a6b3ab4f51b217e8f691b75b8324728b167f0ae27fe5f.png" src="../_images/d15e0c341d8d00005c4a6b3ab4f51b217e8f691b75b8324728b167f0ae27fe5f.png" />
<img alt="../_images/b00ac510d6910c8cb7bb7dacd059d89cc996cc8a388bb0eb35437c20f865fbf0.png" src="../_images/b00ac510d6910c8cb7bb7dacd059d89cc996cc8a388bb0eb35437c20f865fbf0.png" />
</div>
</div>
<p>We see that the gender earnings gap is
12.4%, conditional on hours, age, race, location, education,
union membership, industry, and occupation.
Compared to the gap conditional on only hours, differences in other observable characteristics in the CPS seem unable explain much of the gender earnings gap.</p>
<p>We can repeat the same procedure with another machine learning method
in place of lasso. Let’s try it with neural networks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neural_network</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">model_selection</span>

<span class="n">nnp</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;scaling&quot;</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;nn&quot;</span><span class="p">,</span> <span class="n">neural_network</span><span class="o">.</span><span class="n">MLPRegressor</span><span class="p">((</span><span class="mi">50</span><span class="p">,),</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;logistic&quot;</span><span class="p">,</span>
                                       <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
                                       <span class="n">max_iter</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                       <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.15</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">nndcv</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">nnp</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span> <span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                     <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nn__alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))},</span>
                                     <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                     <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">female</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 4 folds for each of 10 candidates, totalling 40 fits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nnycv</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">nnp</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span> <span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                     <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;nn__alpha&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))},</span>
                                     <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                     <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">logearn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 4 folds for each of 10 candidates, totalling 40 fits
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plotgridcv</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">alphas</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;param_nn__alpha&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="o">-</span><span class="n">g</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">]</span>
    <span class="n">std_error</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;std_test_score&quot;</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span><span class="n">mse</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">mse</span><span class="o">+</span><span class="n">std_error</span><span class="p">,</span> <span class="n">mse</span><span class="o">-</span><span class="n">std_error</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;MSE +/- std error&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">alphas</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alphas</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">plotgridcv</span><span class="p">(</span><span class="n">nnycv</span><span class="p">,</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MSE for log(earn)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">plotgridcv</span><span class="p">(</span><span class="n">nndcv</span><span class="p">,</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MSE for female&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># there are theoretical reasons to choose a smaller regularization</span>
<span class="c1"># than the one that minimizes cv. BUT THIS WAY OF CHOOSING IS ARBITRARY AND MAYBE WRONG</span>
<span class="k">def</span> <span class="nf">pickalphagridcv</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">alphas</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;param_nn__alpha&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
    <span class="n">mses</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">]</span>
    <span class="n">imin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mses</span><span class="p">)</span>
    <span class="n">msemin</span> <span class="o">=</span> <span class="n">mses</span><span class="p">[</span><span class="n">imin</span><span class="p">]</span>
    <span class="n">se</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;std_test_score&quot;</span><span class="p">][</span><span class="n">imin</span><span class="p">]</span>
    <span class="n">alpha</span><span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="n">alpha</span> <span class="k">for</span> <span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">mses</span><span class="p">)</span> <span class="k">if</span> <span class="n">mse</span><span class="o">&lt;</span><span class="n">msemin</span><span class="o">+</span><span class="n">se</span><span class="p">])</span>
    <span class="k">return</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

<span class="n">alphaynn</span> <span class="o">=</span> <span class="n">pickalphagridcv</span><span class="p">(</span><span class="n">nnycv</span><span class="p">)</span>
<span class="n">alphadnn</span> <span class="o">=</span> <span class="n">pickalphagridcv</span><span class="p">(</span><span class="n">nndcv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c0b3462583a7b1b3c61cfec16289390cefd5947dd207a29914ed3ee1bf6fb0fd.png" src="../_images/c0b3462583a7b1b3c61cfec16289390cefd5947dd207a29914ed3ee1bf6fb0fd.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># show results</span>
<span class="n">nny</span> <span class="o">=</span> <span class="n">nnp</span>
<span class="n">nny</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">nn__alpha</span> <span class="o">=</span> <span class="n">alphaynn</span><span class="p">)</span>
<span class="n">nnd</span> <span class="o">=</span> <span class="n">nnp</span>
<span class="n">nnd</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">nn__alpha</span> <span class="o">=</span> <span class="n">alphadnn</span><span class="p">)</span>
<span class="n">pl_nn</span> <span class="o">=</span> <span class="n">partial_linear</span><span class="p">(</span><span class="n">logearn</span><span class="p">,</span> <span class="n">female</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span>
                       <span class="n">nny</span><span class="p">,</span> <span class="n">nnd</span><span class="p">)</span>
<span class="n">pl_nn</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.020</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.020</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   265.2</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Mon, 20 May 2024</td> <th>  Prob (F-statistic):</th>          <td>4.91e-59</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>16:51:11</td>     <th>  Log-Likelihood:    </th>          <td> -13633.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td> 13052</td>      <th>  AIC:               </th>          <td>2.727e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 13051</td>      <th>  BIC:               </th>          <td>2.728e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>              <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
   <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>x1</th> <td>   -0.1997</td> <td>    0.012</td> <td>  -16.284</td> <td> 0.000</td> <td>   -0.224</td> <td>   -0.176</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>4172.973</td> <th>  Durbin-Watson:     </th> <td>   1.726</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>47669.490</td>
</tr>
<tr>
  <th>Skew:</th>           <td>-1.204</td>  <th>  Prob(JB):          </th> <td>    0.00</td> 
</tr>
<tr>
  <th>Kurtosis:</th>       <td>12.047</td>  <th>  Cond. No.          </th> <td>    1.00</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors are heteroscedasticity robust (HC0)</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotpredictions</span><span class="p">(</span><span class="n">pl_nn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2606/3039950914.py:16: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(pl[2][female==0], hist = True, kde = False,
/tmp/ipykernel_2606/3039950914.py:19: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(pl[2][female==1], hist = True, kde = False,
</pre></div>
</div>
<img alt="../_images/66a757ae3e35bd5692c907eda999e0500622b7a50439c994764a92a27c803655.png" src="../_images/66a757ae3e35bd5692c907eda999e0500622b7a50439c994764a92a27c803655.png" />
<img alt="../_images/3828ee8d9b408ce52e512c952a51dec3816459982cab12c9e3b73dfce58a03f1.png" src="../_images/3828ee8d9b408ce52e512c952a51dec3816459982cab12c9e3b73dfce58a03f1.png" />
<img alt="../_images/1a7cf1a78c2edf432ea053da36d583b466bcc0f44892ce5ca0030e9a36525252.png" src="../_images/1a7cf1a78c2edf432ea053da36d583b466bcc0f44892ce5ca0030e9a36525252.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_col</span><span class="p">([</span><span class="n">pl_lasso</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pl_nn</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Lasso&quot;</span><span class="p">,</span> <span class="s2">&quot;Neural Network&quot;</span><span class="p">]</span> <span class="p">,</span><span class="n">stars</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
         <td></td>          <th>Lasso</th>  <th>Neural Network</th>
</tr>
<tr>
  <th>x1</th>              <td>-0.1160</td>     <td>-0.1997</td>   
</tr>
<tr>
  <th></th>               <td>(0.0112)</td>    <td>(0.0123)</td>   
</tr>
<tr>
  <th>R-squared</th>       <td>0.0089</td>      <td>0.0200</td>    
</tr>
<tr>
  <th>R-squared Adj.</th>  <td>0.0088</td>      <td>0.0199</td>    
</tr>
</table></div></div>
</div>
</section>
</section>
<section id="other-applications">
<h3>Other Applications<a class="headerlink" href="#other-applications" title="Permalink to this heading">#</a></h3>
<p>Machine learning can be used to
estimate nuisance functions in many other situations. The partially linear model can easily be
extended to situations where the regressor of interest, <span class="math notranslate nohighlight">\(d\)</span> , is
endogenous and instruments are available. See <span id="id7">[<a class="reference internal" href="#id14" title="Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1):C1-C68, 2018. URL: https://onlinelibrary.wiley.com/doi/abs/10.1111/ectj.12097, arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097, doi:10.1111/ectj.12097.">mlCCD+18</a>]</span>
for details and additional examples.</p>
</section>
</section>
<section id="heterogeneous-effects">
<h2>Heterogeneous Effects<a class="headerlink" href="#heterogeneous-effects" title="Permalink to this heading">#</a></h2>
<p>A third area where economists are using machine learning is to
estimate heterogeneous effects.</p>
<p>Some important papers in this area are <span id="id8">[<a class="reference internal" href="#id18" title="Susan Athey and Guido Imbens. Recursive partitioning for heterogeneous causal effects. Proceedings of the National Academy of Sciences, 113(27):7353–7360, 2016. URL: http://www.pnas.org/content/113/27/7353, arXiv:http://www.pnas.org/content/113/27/7353.full.pdf, doi:10.1073/pnas.1510489113.">mlAI16</a>]</span> ,
<span id="id9">[<a class="reference internal" href="#id17" title="Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 0(0):1-15, 2018. URL: https://doi.org/10.1080/01621459.2017.1319839, arXiv:https://doi.org/10.1080/01621459.2017.1319839, doi:10.1080/01621459.2017.1319839.">mlWA18</a>]</span> , and <span id="id10">[<a class="reference internal" href="#id16" title="Victor Chernozhukov, Mert Demirer, Esther Duflo, and Iván Fernández-Val. Generic machine learning inference on heterogenous treatment effects in randomized experimentsxo. Working Paper 24678, National Bureau of Economic Research, June 2018. URL: http://www.nber.org/papers/w24678, doi:10.3386/w24678.">mlCDDFV18</a>]</span> .</p>
<p>We will explore this is more depth in <a class="reference internal" href="heterogeneity.html"><span class="doc">heterogeneity</span></a>.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<div class="docutils container" id="id11">
<dl class="citation">
<dt class="label" id="id18"><span class="brackets"><a class="fn-backref" href="#id8">mlAI16</a></span></dt>
<dd><p>Susan Athey and Guido Imbens. Recursive partitioning for heterogeneous causal effects. <em>Proceedings of the National Academy of Sciences</em>, 113(27):7353–7360, 2016. URL: <a class="reference external" href="http://www.pnas.org/content/113/27/7353">http://www.pnas.org/content/113/27/7353</a>, <a class="reference external" href="https://arxiv.org/abs/http://www.pnas.org/content/113/27/7353.full.pdf">arXiv:http://www.pnas.org/content/113/27/7353.full.pdf</a>, <a class="reference external" href="https://doi.org/10.1073/pnas.1510489113">doi:10.1073/pnas.1510489113</a>.</p>
</dd>
<dt class="label" id="id14"><span class="brackets">mlCCD+18</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id7">2</a>)</span></dt>
<dd><p>Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. Double/debiased machine learning for treatment and structural parameters. <em>The Econometrics Journal</em>, 21(1):C1–C68, 2018. URL: <a class="reference external" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/ectj.12097">https://onlinelibrary.wiley.com/doi/abs/10.1111/ectj.12097</a>, <a class="reference external" href="https://arxiv.org/abs/https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097">arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097</a>, <a class="reference external" href="https://doi.org/10.1111/ectj.12097">doi:10.1111/ectj.12097</a>.</p>
</dd>
<dt class="label" id="id16"><span class="brackets"><a class="fn-backref" href="#id10">mlCDDFV18</a></span></dt>
<dd><p>Victor Chernozhukov, Mert Demirer, Esther Duflo, and Iván Fernández-Val. Generic machine learning inference on heterogenous treatment effects in randomized experimentsxo. Working Paper 24678, National Bureau of Economic Research, June 2018. URL: <a class="reference external" href="http://www.nber.org/papers/w24678">http://www.nber.org/papers/w24678</a>, <a class="reference external" href="https://doi.org/10.3386/w24678">doi:10.3386/w24678</a>.</p>
</dd>
<dt class="label" id="id21"><span class="brackets"><a class="fn-backref" href="#id6">mlCHS16</a></span></dt>
<dd><p>Victor Chernozhukov, Chris Hansen, and Martin Spindler. hdm: high-dimensional metrics. <em>R Journal</em>, 8(2):185–199, 2016. URL: <a class="reference external" href="https://journal.r-project.org/archive/2016/RJ-2016-040/index.html">https://journal.r-project.org/archive/2016/RJ-2016-040/index.html</a>.</p>
</dd>
<dt class="label" id="id12"><span class="brackets"><a class="fn-backref" href="#id4">mlKLL+17</a></span></dt>
<dd><p>Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. Human Decisions and Machine Predictions*. <em>The Quarterly Journal of Economics</em>, 133(1):237–293, 08 2017. URL: <a class="reference external" href="https://dx.doi.org/10.1093/qje/qjx032">https://dx.doi.org/10.1093/qje/qjx032</a>, <a class="reference external" href="https://arxiv.org/abs/http://oup.prod.sis.lan/qje/article-pdf/133/1/237/24246094/qjx032.pdf">arXiv:http://oup.prod.sis.lan/qje/article-pdf/133/1/237/24246094/qjx032.pdf</a>, <a class="reference external" href="https://doi.org/10.1093/qje/qjx032">doi:10.1093/qje/qjx032</a>.</p>
</dd>
<dt class="label" id="id13"><span class="brackets">mlKLMO15</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>,<a href="#id3">3</a>)</span></dt>
<dd><p>Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, and Ziad Obermeyer. Prediction policy problems. <em>American Economic Review</em>, 105(5):491–95, May 2015. URL: <a class="reference external" href="http://www.aeaweb.org/articles?id=10.1257/aer.p20151023">http://www.aeaweb.org/articles?id=10.1257/aer.p20151023</a>, <a class="reference external" href="https://doi.org/10.1257/aer.p20151023">doi:10.1257/aer.p20151023</a>.</p>
</dd>
<dt class="label" id="id17"><span class="brackets"><a class="fn-backref" href="#id9">mlWA18</a></span></dt>
<dd><p>Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using random forests. <em>Journal of the American Statistical Association</em>, 0(0):1–15, 2018. URL: <a class="reference external" href="https://doi.org/10.1080/01621459.2017.1319839">https://doi.org/10.1080/01621459.2017.1319839</a>, <a class="reference external" href="https://arxiv.org/abs/https://doi.org/10.1080/01621459.2017.1319839">arXiv:https://doi.org/10.1080/01621459.2017.1319839</a>, <a class="reference external" href="https://doi.org/10.1080/01621459.2017.1319839">doi:10.1080/01621459.2017.1319839</a>.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./applications"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive persistent" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/index.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/overview.html">
   Course Description
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/cloud_setup.html">
   Cloud Setup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/local_install.html">
   Local Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/troubleshooting.html">
   Troubleshooting
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Python Fundamentals
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../python_fundamentals/index.html">
   Python Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_fundamentals/basics.html">
   Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_fundamentals/collections.html">
   Collections
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_fundamentals/control_flow.html">
   Control Flow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../python_fundamentals/functions.html">
   Functions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scientific Computing
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../scientific/index.html">
   Scientific Computing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../scientific/numpy_arrays.html">
   Introduction to Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../scientific/plotting.html">
   Plotting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../scientific/applied_linalg.html">
   Applied Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../scientific/randomness.html">
   Randomness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../scientific/optimization.html">
   Optimization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pandas
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/index.html">
   DataFrames and Series in Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/basics.html">
   Basic Functionality
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/the_index.html">
   The Index
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/storage_formats.html">
   Storage Formats
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/data_clean.html">
   Cleaning Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/reshape.html">
   Reshape
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/merge.html">
   Merge
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/groupby.html">
   GroupBy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pandas/timeseries.html">
   Time series
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data Science Tools
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/index.html">
   Data Science Tools
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/matplotlib.html">
   Intermediate Plotting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/maps.html">
   Mapping in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/visualization_rules.html">
   Data Visualization: Rules and Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/regression.html">
   Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tools/classification.html">
   Classification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Applications
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Applications
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   Machine Learning in Economics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="networks.html">
   Social and Economic Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="recidivism.html">
   Case Study: Recidivism
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="working_with_text.html">
   Working with Text
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="heterogeneity.html">
   Heterogeneous Effects
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="../index.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                    <!-- <li class="btn__search">
                        <form action="../search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off">
                            <i data-feather="search"></i>
                        </form>
                    </li> -->
                </ul>

                <ul class="qe-toolbar__links">
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/applications/ml_in_economics.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li data-tippy-content="Download PDF" onClick="window.print()"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-datascience.myst/tree/main/lectures/applications/ml_in_economics.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://mybinder.org/v2/gh/QuantEcon/lecture-datascience.notebooks/main?urlpath=tree/applications/ml_in_economics.ipynb">BinderHub</option>
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-datascience.notebooks/blob/main/applications/ml_in_economics.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-datascience.notebooks" data-urlpath="tree/lecture-datascience.notebooks/applications/ml_in_economics.ipynb" data-branch=main>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://mybinder.org/v2/gh/QuantEcon/lecture-datascience.notebooks/main?urlpath=tree/applications/ml_in_economics.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "applications/ml_in_economics";
                const repoURL = "https://github.com/QuantEcon/lecture-datascience.notebooks";
                const urlPath = "tree/lecture-datascience.notebooks/applications/ml_in_economics.ipynb";
                const branch = "main"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>